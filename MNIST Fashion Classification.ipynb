{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install tensorflow==2.0.0-rc1 --quiet\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_raw, y_train), (X_test_raw, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale\n",
    "X_train = X_train_raw / 255.0\n",
    "X_test = X_test_raw / 255.0\n",
    "\n",
    "# reshape to use in Dense layers\n",
    "X_train = X_train.reshape(X_train.shape[0], 28*28)\n",
    "X_test = X_test.reshape(X_test.shape[0], 28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert labels to numeric\n",
    "y_train_cat = to_categorical(y_train, 10)\n",
    "y_test_cat = to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1, ..., 8, 1, 5], dtype=uint8)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# want to keep y_test unaltered for use in evaluation\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1: 5 layers, Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = Sequential()\n",
    "model_1.add(Dense(128, input_dim = X_train.shape[1], activation = 'relu'))\n",
    "model_1.add(Dense(64, activation = 'relu'))\n",
    "model_1.add(Dense(64, activation = 'relu'))\n",
    "model_1.add(Dense(32, activation = 'relu'))\n",
    "model_1.add(Dense(10, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x000002832264C9D8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x000002832264C9D8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.6216 - accuracy: 0.7818 - val_loss: 0.4759 - val_accuracy: 0.8347\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 2s 32us/sample - loss: 0.4130 - accuracy: 0.8548 - val_loss: 0.4207 - val_accuracy: 0.8457\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.3669 - accuracy: 0.8683 - val_loss: 0.3856 - val_accuracy: 0.8596\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.3343 - accuracy: 0.8790 - val_loss: 0.3843 - val_accuracy: 0.8621\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.3151 - accuracy: 0.8846 - val_loss: 0.3662 - val_accuracy: 0.8675\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.2975 - accuracy: 0.8915 - val_loss: 0.3453 - val_accuracy: 0.8738\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 2s 32us/sample - loss: 0.2866 - accuracy: 0.8943 - val_loss: 0.3397 - val_accuracy: 0.8760\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 2s 32us/sample - loss: 0.2722 - accuracy: 0.8982 - val_loss: 0.3478 - val_accuracy: 0.8761\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.2673 - accuracy: 0.9004 - val_loss: 0.3398 - val_accuracy: 0.8774\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.2588 - accuracy: 0.9027 - val_loss: 0.3558 - val_accuracy: 0.8751\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 2s 32us/sample - loss: 0.2489 - accuracy: 0.9068 - val_loss: 0.3498 - val_accuracy: 0.8781\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.2428 - accuracy: 0.9095 - val_loss: 0.3247 - val_accuracy: 0.8843\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 2s 32us/sample - loss: 0.2348 - accuracy: 0.9131 - val_loss: 0.3421 - val_accuracy: 0.8812\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 2s 32us/sample - loss: 0.2276 - accuracy: 0.9149 - val_loss: 0.3353 - val_accuracy: 0.8869\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 2s 32us/sample - loss: 0.2203 - accuracy: 0.9171 - val_loss: 0.3273 - val_accuracy: 0.8882\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.2152 - accuracy: 0.9189 - val_loss: 0.3285 - val_accuracy: 0.8838\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.2104 - accuracy: 0.9220 - val_loss: 0.3317 - val_accuracy: 0.8900\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.2028 - accuracy: 0.9226 - val_loss: 0.3336 - val_accuracy: 0.8865\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.2018 - accuracy: 0.9245 - val_loss: 0.3313 - val_accuracy: 0.8886\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 2s 31us/sample - loss: 0.1974 - accuracy: 0.9256 - val_loss: 0.3621 - val_accuracy: 0.8811\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.1911 - accuracy: 0.9287 - val_loss: 0.3467 - val_accuracy: 0.8887\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.1861 - accuracy: 0.9293 - val_loss: 0.3505 - val_accuracy: 0.8840\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.1784 - accuracy: 0.9323 - val_loss: 0.3449 - val_accuracy: 0.8894\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.1763 - accuracy: 0.9332 - val_loss: 0.3563 - val_accuracy: 0.8889\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.1761 - accuracy: 0.9333 - val_loss: 0.3401 - val_accuracy: 0.8923\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 2s 37us/sample - loss: 0.1698 - accuracy: 0.9357 - val_loss: 0.3666 - val_accuracy: 0.8880\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 2s 41us/sample - loss: 0.1622 - accuracy: 0.9388 - val_loss: 0.3617 - val_accuracy: 0.8846\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 2s 37us/sample - loss: 0.1613 - accuracy: 0.9394 - val_loss: 0.3633 - val_accuracy: 0.8900\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 0.1587 - accuracy: 0.9397 - val_loss: 0.3882 - val_accuracy: 0.8889\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.1513 - accuracy: 0.9437 - val_loss: 0.3667 - val_accuracy: 0.8919\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 3s 47us/sample - loss: 0.1470 - accuracy: 0.9444 - val_loss: 0.3904 - val_accuracy: 0.8909\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 2s 41us/sample - loss: 0.1460 - accuracy: 0.9450 - val_loss: 0.3986 - val_accuracy: 0.8855\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.1409 - accuracy: 0.9466 - val_loss: 0.4024 - val_accuracy: 0.8882\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.1380 - accuracy: 0.9478 - val_loss: 0.3888 - val_accuracy: 0.8913\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.1346 - accuracy: 0.9484 - val_loss: 0.4390 - val_accuracy: 0.8795\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.1373 - accuracy: 0.9472 - val_loss: 0.3941 - val_accuracy: 0.8925\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.1279 - accuracy: 0.9518 - val_loss: 0.4294 - val_accuracy: 0.8876\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.1284 - accuracy: 0.9502 - val_loss: 0.4359 - val_accuracy: 0.8843\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.1284 - accuracy: 0.9519 - val_loss: 0.4257 - val_accuracy: 0.8889\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.1239 - accuracy: 0.9532 - val_loss: 0.4462 - val_accuracy: 0.8818\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.1185 - accuracy: 0.9550 - val_loss: 0.4030 - val_accuracy: 0.8932\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.1220 - accuracy: 0.9528 - val_loss: 0.4363 - val_accuracy: 0.8753\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.1152 - accuracy: 0.9557 - val_loss: 0.4406 - val_accuracy: 0.8881\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.1099 - accuracy: 0.9577 - val_loss: 0.4529 - val_accuracy: 0.8904\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.1090 - accuracy: 0.9590 - val_loss: 0.4450 - val_accuracy: 0.8858\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.1066 - accuracy: 0.9592 - val_loss: 0.4763 - val_accuracy: 0.8907\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.1060 - accuracy: 0.9598 - val_loss: 0.4792 - val_accuracy: 0.8859\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.1034 - accuracy: 0.9602 - val_loss: 0.4704 - val_accuracy: 0.8884\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.1034 - accuracy: 0.9606 - val_loss: 0.4957 - val_accuracy: 0.8848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.1065 - accuracy: 0.9602 - val_loss: 0.4976 - val_accuracy: 0.8900\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.1014 - accuracy: 0.9618 - val_loss: 0.5030 - val_accuracy: 0.8924\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 0.0942 - accuracy: 0.9645 - val_loss: 0.4732 - val_accuracy: 0.8887\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 3s 51us/sample - loss: 0.0947 - accuracy: 0.9640 - val_loss: 0.5416 - val_accuracy: 0.8870\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 3s 50us/sample - loss: 0.0911 - accuracy: 0.9649 - val_loss: 0.4978 - val_accuracy: 0.8871\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 2s 40us/sample - loss: 0.0896 - accuracy: 0.9658 - val_loss: 0.5298 - val_accuracy: 0.8868\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.0884 - accuracy: 0.9666 - val_loss: 0.5151 - val_accuracy: 0.8889\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.0887 - accuracy: 0.9659 - val_loss: 0.5423 - val_accuracy: 0.8869\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.0895 - accuracy: 0.9665 - val_loss: 0.5286 - val_accuracy: 0.8889\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.0849 - accuracy: 0.9675 - val_loss: 0.5281 - val_accuracy: 0.8920\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.0820 - accuracy: 0.9690 - val_loss: 0.5301 - val_accuracy: 0.8895\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.0810 - accuracy: 0.9696 - val_loss: 0.5879 - val_accuracy: 0.8825\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.0847 - accuracy: 0.9681 - val_loss: 0.5859 - val_accuracy: 0.8866\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.0804 - accuracy: 0.9694 - val_loss: 0.5485 - val_accuracy: 0.8886\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.0829 - accuracy: 0.9679 - val_loss: 0.5448 - val_accuracy: 0.8889\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 2s 37us/sample - loss: 0.0772 - accuracy: 0.9707 - val_loss: 0.5377 - val_accuracy: 0.8918\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.0759 - accuracy: 0.9720 - val_loss: 0.5523 - val_accuracy: 0.8874\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.0801 - accuracy: 0.9692 - val_loss: 0.5696 - val_accuracy: 0.8884\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.0713 - accuracy: 0.9732 - val_loss: 0.5659 - val_accuracy: 0.8898\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.0680 - accuracy: 0.9740 - val_loss: 0.6224 - val_accuracy: 0.8902\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.0671 - accuracy: 0.9749 - val_loss: 0.5793 - val_accuracy: 0.8918\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.0753 - accuracy: 0.9713 - val_loss: 0.5985 - val_accuracy: 0.8878\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.0682 - accuracy: 0.9741 - val_loss: 0.6792 - val_accuracy: 0.8823\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.0738 - accuracy: 0.9721 - val_loss: 0.6526 - val_accuracy: 0.8861\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.0642 - accuracy: 0.9758 - val_loss: 0.5779 - val_accuracy: 0.8890\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 0.0649 - accuracy: 0.9761 - val_loss: 0.6392 - val_accuracy: 0.8866\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 2s 38us/sample - loss: 0.0678 - accuracy: 0.9746 - val_loss: 0.6358 - val_accuracy: 0.8883\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.0669 - accuracy: 0.9750 - val_loss: 0.6313 - val_accuracy: 0.8900\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.0601 - accuracy: 0.9775 - val_loss: 0.6272 - val_accuracy: 0.8876\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.0608 - accuracy: 0.9769 - val_loss: 0.6764 - val_accuracy: 0.8897\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.0674 - accuracy: 0.9748 - val_loss: 0.6376 - val_accuracy: 0.8878\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.0655 - accuracy: 0.9758 - val_loss: 0.6442 - val_accuracy: 0.8902\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.0530 - accuracy: 0.9800 - val_loss: 0.6637 - val_accuracy: 0.8865\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.0614 - accuracy: 0.9761 - val_loss: 0.6637 - val_accuracy: 0.8874\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.0540 - accuracy: 0.9798 - val_loss: 0.6720 - val_accuracy: 0.8885\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.0608 - accuracy: 0.9765 - val_loss: 0.6508 - val_accuracy: 0.8850\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.0559 - accuracy: 0.9790 - val_loss: 0.7102 - val_accuracy: 0.8812\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 2s 37us/sample - loss: 0.0555 - accuracy: 0.9795 - val_loss: 0.7064 - val_accuracy: 0.8833\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.0555 - accuracy: 0.9788 - val_loss: 0.6571 - val_accuracy: 0.8833\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.0707 - accuracy: 0.9741 - val_loss: 0.6821 - val_accuracy: 0.8810\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.0497 - accuracy: 0.9819 - val_loss: 0.7088 - val_accuracy: 0.8887\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 2s 37us/sample - loss: 0.0531 - accuracy: 0.9798 - val_loss: 0.6833 - val_accuracy: 0.8905\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 0.0529 - accuracy: 0.9807 - val_loss: 0.7120 - val_accuracy: 0.8861\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.0533 - accuracy: 0.9796 - val_loss: 0.6769 - val_accuracy: 0.8794\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.0481 - accuracy: 0.9818 - val_loss: 0.6730 - val_accuracy: 0.8887\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.0555 - accuracy: 0.9793 - val_loss: 0.7238 - val_accuracy: 0.8820\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.0498 - accuracy: 0.9813 - val_loss: 0.7225 - val_accuracy: 0.8863\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.0501 - accuracy: 0.9807 - val_loss: 0.7517 - val_accuracy: 0.8885\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 2s 38us/sample - loss: 0.0500 - accuracy: 0.9817 - val_loss: 0.7181 - val_accuracy: 0.8843\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 2s 37us/sample - loss: 0.0505 - accuracy: 0.9814 - val_loss: 0.6691 - val_accuracy: 0.8879\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.0416 - accuracy: 0.9846 - val_loss: 0.7687 - val_accuracy: 0.8884\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x28322667448>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "\n",
    "model_1.fit(X_train, y_train_cat, validation_data = (X_test, y_test_cat), \n",
    "         epochs = 100, batch_size = 200, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Loss: 0.0.0416 <br>\n",
    "Train Accuracy: 0.9846 <br>\n",
    "Test Loss: 0.7687 <br>\n",
    "Test Accuracy: 0.8884"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2: 5 layers, RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = Sequential()\n",
    "model_2.add(Dense(128, input_dim = X_train.shape[1], activation = 'relu'))\n",
    "model_2.add(Dense(64, activation = 'relu'))\n",
    "model_2.add(Dense(64, activation = 'relu'))\n",
    "model_2.add(Dense(32, activation = 'relu'))\n",
    "model_2.add(Dense(10, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000028323445708> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000028323445708> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "60000/60000 [==============================] - 3s 51us/sample - loss: 0.6557 - accuracy: 0.7659 - val_loss: 0.5027 - val_accuracy: 0.8126\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.4351 - accuracy: 0.8415 - val_loss: 0.4194 - val_accuracy: 0.8474\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.3791 - accuracy: 0.8575 - val_loss: 0.4836 - val_accuracy: 0.8143\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.3507 - accuracy: 0.8703 - val_loss: 0.3871 - val_accuracy: 0.8584\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 2s 38us/sample - loss: 0.3272 - accuracy: 0.8781 - val_loss: 0.3767 - val_accuracy: 0.8654\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 2s 40us/sample - loss: 0.3113 - accuracy: 0.8845 - val_loss: 0.3765 - val_accuracy: 0.8657\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 2s 40us/sample - loss: 0.2961 - accuracy: 0.8890 - val_loss: 0.3486 - val_accuracy: 0.8764\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 2s 37us/sample - loss: 0.2834 - accuracy: 0.8942 - val_loss: 0.3453 - val_accuracy: 0.8792\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.2723 - accuracy: 0.8985 - val_loss: 0.3838 - val_accuracy: 0.8709\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 2s 37us/sample - loss: 0.2627 - accuracy: 0.9022 - val_loss: 0.3604 - val_accuracy: 0.8716\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.2550 - accuracy: 0.9044 - val_loss: 0.3275 - val_accuracy: 0.8841\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.2461 - accuracy: 0.9069 - val_loss: 0.3310 - val_accuracy: 0.8856\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.2395 - accuracy: 0.9105 - val_loss: 0.3561 - val_accuracy: 0.8743\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 2s 37us/sample - loss: 0.2316 - accuracy: 0.9123 - val_loss: 0.3402 - val_accuracy: 0.8856\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 2s 38us/sample - loss: 0.2250 - accuracy: 0.9155 - val_loss: 0.3321 - val_accuracy: 0.8877\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.2192 - accuracy: 0.9167 - val_loss: 0.3678 - val_accuracy: 0.8781\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.2125 - accuracy: 0.9200 - val_loss: 0.3391 - val_accuracy: 0.8847\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.2077 - accuracy: 0.9214 - val_loss: 0.3650 - val_accuracy: 0.8849\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.2016 - accuracy: 0.9236 - val_loss: 0.3687 - val_accuracy: 0.8799\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 2s 37us/sample - loss: 0.1959 - accuracy: 0.9253 - val_loss: 0.3780 - val_accuracy: 0.8839\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.1923 - accuracy: 0.9276 - val_loss: 0.3695 - val_accuracy: 0.8863\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.1882 - accuracy: 0.9287 - val_loss: 0.3699 - val_accuracy: 0.8836\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 2s 38us/sample - loss: 0.1840 - accuracy: 0.9299 - val_loss: 0.3638 - val_accuracy: 0.8913\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 2s 37us/sample - loss: 0.1779 - accuracy: 0.9337 - val_loss: 0.3777 - val_accuracy: 0.8816\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.1759 - accuracy: 0.9331 - val_loss: 0.3656 - val_accuracy: 0.8899\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.1715 - accuracy: 0.9348 - val_loss: 0.3823 - val_accuracy: 0.8884\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 2s 37us/sample - loss: 0.1687 - accuracy: 0.9355 - val_loss: 0.4044 - val_accuracy: 0.8862\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 2s 37us/sample - loss: 0.1645 - accuracy: 0.9372 - val_loss: 0.3795 - val_accuracy: 0.8873\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.1618 - accuracy: 0.9382 - val_loss: 0.4108 - val_accuracy: 0.8856\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.1575 - accuracy: 0.9394 - val_loss: 0.3763 - val_accuracy: 0.8922\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.1538 - accuracy: 0.9404 - val_loss: 0.4056 - val_accuracy: 0.8887\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 2s 37us/sample - loss: 0.1527 - accuracy: 0.9418 - val_loss: 0.4315 - val_accuracy: 0.8860\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.1491 - accuracy: 0.9436 - val_loss: 0.4553 - val_accuracy: 0.8921\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.1477 - accuracy: 0.9435 - val_loss: 0.4266 - val_accuracy: 0.8926\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 2s 37us/sample - loss: 0.1446 - accuracy: 0.9455 - val_loss: 0.4495 - val_accuracy: 0.8910\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.1433 - accuracy: 0.9464 - val_loss: 0.4643 - val_accuracy: 0.8908\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 3s 49us/sample - loss: 0.1389 - accuracy: 0.9471 - val_loss: 0.4316 - val_accuracy: 0.8937\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 3s 46us/sample - loss: 0.1369 - accuracy: 0.9482 - val_loss: 0.4566 - val_accuracy: 0.8870\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 2s 38us/sample - loss: 0.1355 - accuracy: 0.9478 - val_loss: 0.4487 - val_accuracy: 0.8919\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.1329 - accuracy: 0.9495 - val_loss: 0.4684 - val_accuracy: 0.8862\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 2s 37us/sample - loss: 0.1302 - accuracy: 0.9508 - val_loss: 0.5005 - val_accuracy: 0.8900\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 2s 37us/sample - loss: 0.1265 - accuracy: 0.9522 - val_loss: 0.5105 - val_accuracy: 0.8869\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 2s 37us/sample - loss: 0.1271 - accuracy: 0.9520 - val_loss: 0.5673 - val_accuracy: 0.8885\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 2s 37us/sample - loss: 0.1258 - accuracy: 0.9531 - val_loss: 0.5035 - val_accuracy: 0.8851\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 2s 37us/sample - loss: 0.1226 - accuracy: 0.9531 - val_loss: 0.5531 - val_accuracy: 0.8874\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.1214 - accuracy: 0.9545 - val_loss: 0.5468 - val_accuracy: 0.8913\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.1185 - accuracy: 0.9550 - val_loss: 0.5552 - val_accuracy: 0.8903\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 2s 38us/sample - loss: 0.1181 - accuracy: 0.9552 - val_loss: 0.6306 - val_accuracy: 0.8830\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 2s 37us/sample - loss: 0.1153 - accuracy: 0.9563 - val_loss: 0.6023 - val_accuracy: 0.8863\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.1145 - accuracy: 0.9565 - val_loss: 0.5612 - val_accuracy: 0.8895\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.1117 - accuracy: 0.9571 - val_loss: 0.6428 - val_accuracy: 0.8891\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.1111 - accuracy: 0.9574 - val_loss: 0.5511 - val_accuracy: 0.8927\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.1095 - accuracy: 0.9582 - val_loss: 0.5966 - val_accuracy: 0.8893\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.1072 - accuracy: 0.9593 - val_loss: 0.6248 - val_accuracy: 0.8903\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.1072 - accuracy: 0.9608 - val_loss: 0.5762 - val_accuracy: 0.8777\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.1052 - accuracy: 0.9611 - val_loss: 0.6070 - val_accuracy: 0.8909\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.1055 - accuracy: 0.9606 - val_loss: 0.6973 - val_accuracy: 0.8873\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.1036 - accuracy: 0.9606 - val_loss: 0.6308 - val_accuracy: 0.8902\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.1028 - accuracy: 0.9609 - val_loss: 0.6367 - val_accuracy: 0.8862\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 0.1006 - accuracy: 0.9617 - val_loss: 0.7073 - val_accuracy: 0.8877\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 2s 41us/sample - loss: 0.0994 - accuracy: 0.9626 - val_loss: 0.7447 - val_accuracy: 0.8933\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.0988 - accuracy: 0.9631 - val_loss: 0.6265 - val_accuracy: 0.8893\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 2s 38us/sample - loss: 0.0978 - accuracy: 0.9630 - val_loss: 0.7019 - val_accuracy: 0.8866\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 2s 40us/sample - loss: 0.0953 - accuracy: 0.9645 - val_loss: 0.6231 - val_accuracy: 0.8914\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 2s 38us/sample - loss: 0.0943 - accuracy: 0.9648 - val_loss: 0.6496 - val_accuracy: 0.8899\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.0927 - accuracy: 0.9647 - val_loss: 0.7122 - val_accuracy: 0.8894\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.0942 - accuracy: 0.9652 - val_loss: 0.7146 - val_accuracy: 0.8881\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.0911 - accuracy: 0.9663 - val_loss: 0.7431 - val_accuracy: 0.8907\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 2s 37us/sample - loss: 0.0907 - accuracy: 0.9667 - val_loss: 0.7346 - val_accuracy: 0.8952\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.0918 - accuracy: 0.9667 - val_loss: 0.7707 - val_accuracy: 0.8944\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.0900 - accuracy: 0.9660 - val_loss: 0.7442 - val_accuracy: 0.8871\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.0902 - accuracy: 0.9667 - val_loss: 0.7799 - val_accuracy: 0.8769\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 2s 38us/sample - loss: 0.0869 - accuracy: 0.9670 - val_loss: 0.8321 - val_accuracy: 0.8867\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.0869 - accuracy: 0.9682 - val_loss: 0.8031 - val_accuracy: 0.8873\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.0838 - accuracy: 0.9692 - val_loss: 0.7291 - val_accuracy: 0.8874\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.0848 - accuracy: 0.9686 - val_loss: 0.8063 - val_accuracy: 0.8921\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.0841 - accuracy: 0.9687 - val_loss: 0.8222 - val_accuracy: 0.8897\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.0821 - accuracy: 0.9689 - val_loss: 0.7944 - val_accuracy: 0.8901\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 2s 30us/sample - loss: 0.0821 - accuracy: 0.9703 - val_loss: 0.8281 - val_accuracy: 0.8898\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.0815 - accuracy: 0.9692 - val_loss: 0.7829 - val_accuracy: 0.8893\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.0816 - accuracy: 0.9698 - val_loss: 0.7181 - val_accuracy: 0.8913\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 0.0769 - accuracy: 0.9711 - val_loss: 0.8337 - val_accuracy: 0.8891\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.0792 - accuracy: 0.9709 - val_loss: 0.8316 - val_accuracy: 0.8889\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.0804 - accuracy: 0.9706 - val_loss: 0.8270 - val_accuracy: 0.8858\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.0772 - accuracy: 0.9714 - val_loss: 0.8725 - val_accuracy: 0.8908\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.0763 - accuracy: 0.9728 - val_loss: 0.8645 - val_accuracy: 0.8892\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.0765 - accuracy: 0.9715 - val_loss: 0.9031 - val_accuracy: 0.8883\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.0745 - accuracy: 0.9729 - val_loss: 0.8090 - val_accuracy: 0.8854\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.0759 - accuracy: 0.9718 - val_loss: 1.0171 - val_accuracy: 0.8895\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.0746 - accuracy: 0.9737 - val_loss: 0.8881 - val_accuracy: 0.8808\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.0743 - accuracy: 0.9735 - val_loss: 0.9832 - val_accuracy: 0.8882\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.0750 - accuracy: 0.9726 - val_loss: 0.9505 - val_accuracy: 0.8898\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 0.0731 - accuracy: 0.9737 - val_loss: 0.8798 - val_accuracy: 0.8939\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 0.0722 - accuracy: 0.9740 - val_loss: 0.9675 - val_accuracy: 0.8827\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.0735 - accuracy: 0.9736 - val_loss: 0.9951 - val_accuracy: 0.8824\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.0689 - accuracy: 0.9749 - val_loss: 0.9961 - val_accuracy: 0.8888\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.0701 - accuracy: 0.9744 - val_loss: 0.9301 - val_accuracy: 0.8893\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.0705 - accuracy: 0.9747 - val_loss: 0.9641 - val_accuracy: 0.8891\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.0686 - accuracy: 0.9744 - val_loss: 1.0037 - val_accuracy: 0.8845\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.0698 - accuracy: 0.9748 - val_loss: 1.0122 - val_accuracy: 0.8924\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2832343ce08>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.compile(loss = 'categorical_crossentropy', optimizer = 'RMSprop', metrics = ['accuracy'])\n",
    "\n",
    "model_2.fit(X_train, y_train_cat, validation_data = (X_test, y_test_cat), \n",
    "         epochs = 100, batch_size = 200, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Loss: 0.0698 <br>\n",
    "Train Accuracy: 0.9748 <br>\n",
    "Test Loss: 1.0122 <br>\n",
    "Test Accuracy: 0.8924 <br>\n",
    "\n",
    "Using RMSprop as the optimizer very slightly increases test accuracy, but the loss is greater."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3: 5 layers, SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3 = Sequential()\n",
    "model_3.add(Dense(128, input_dim = X_train.shape[1], activation = 'relu'))\n",
    "model_3.add(Dense(64, activation = 'relu'))\n",
    "model_3.add(Dense(64, activation = 'relu'))\n",
    "model_3.add(Dense(32, activation = 'relu'))\n",
    "model_3.add(Dense(10, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x000002833E508B88> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x000002833E508B88> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 1.5913 - accuracy: 0.4693 - val_loss: 0.9736 - val_accuracy: 0.6493\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.8093 - accuracy: 0.7107 - val_loss: 0.7368 - val_accuracy: 0.7381\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.6658 - accuracy: 0.7682 - val_loss: 0.6511 - val_accuracy: 0.7695\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.5925 - accuracy: 0.7960 - val_loss: 0.6240 - val_accuracy: 0.7704\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.5481 - accuracy: 0.8095 - val_loss: 0.5487 - val_accuracy: 0.8110\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.5191 - accuracy: 0.8191 - val_loss: 0.5274 - val_accuracy: 0.8160\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.4960 - accuracy: 0.8253 - val_loss: 0.5159 - val_accuracy: 0.8188\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.4798 - accuracy: 0.8307 - val_loss: 0.5163 - val_accuracy: 0.8209\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.4658 - accuracy: 0.8357 - val_loss: 0.4821 - val_accuracy: 0.8324\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.4563 - accuracy: 0.8389 - val_loss: 0.4811 - val_accuracy: 0.8309\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.4430 - accuracy: 0.8444 - val_loss: 0.4861 - val_accuracy: 0.8293\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.4341 - accuracy: 0.8474 - val_loss: 0.4539 - val_accuracy: 0.8390\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 0.4257 - accuracy: 0.8506 - val_loss: 0.4509 - val_accuracy: 0.8430\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 0.4197 - accuracy: 0.8532 - val_loss: 0.4554 - val_accuracy: 0.8393\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.4128 - accuracy: 0.8547 - val_loss: 0.4410 - val_accuracy: 0.8416\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.4064 - accuracy: 0.8577 - val_loss: 0.4533 - val_accuracy: 0.8360\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.3999 - accuracy: 0.8600 - val_loss: 0.4459 - val_accuracy: 0.8395\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.3956 - accuracy: 0.8626 - val_loss: 0.4428 - val_accuracy: 0.8431\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.3895 - accuracy: 0.8640 - val_loss: 0.4485 - val_accuracy: 0.8406\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 0.3859 - accuracy: 0.8640 - val_loss: 0.4206 - val_accuracy: 0.8509\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 2s 25us/sample - loss: 0.3800 - accuracy: 0.8651 - val_loss: 0.4215 - val_accuracy: 0.8506\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 0.3787 - accuracy: 0.8664 - val_loss: 0.4276 - val_accuracy: 0.8489\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 0.3730 - accuracy: 0.8693 - val_loss: 0.4288 - val_accuracy: 0.8450\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.3698 - accuracy: 0.8702 - val_loss: 0.4134 - val_accuracy: 0.8512\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.3667 - accuracy: 0.8711 - val_loss: 0.4168 - val_accuracy: 0.8516\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 0.3610 - accuracy: 0.8727 - val_loss: 0.4022 - val_accuracy: 0.8560\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 0.3586 - accuracy: 0.8741 - val_loss: 0.4006 - val_accuracy: 0.8582\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.3560 - accuracy: 0.8745 - val_loss: 0.4000 - val_accuracy: 0.8584\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.3525 - accuracy: 0.8763 - val_loss: 0.4195 - val_accuracy: 0.8515\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 0.3498 - accuracy: 0.8770 - val_loss: 0.4033 - val_accuracy: 0.8575\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.3460 - accuracy: 0.8768 - val_loss: 0.3949 - val_accuracy: 0.8610\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.3430 - accuracy: 0.8795 - val_loss: 0.3970 - val_accuracy: 0.8600\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.3398 - accuracy: 0.8799 - val_loss: 0.3943 - val_accuracy: 0.8589\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.3382 - accuracy: 0.8802 - val_loss: 0.3812 - val_accuracy: 0.8648\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.3347 - accuracy: 0.8822 - val_loss: 0.3874 - val_accuracy: 0.8638\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.3325 - accuracy: 0.8829 - val_loss: 0.3806 - val_accuracy: 0.8662\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.3309 - accuracy: 0.8830 - val_loss: 0.3871 - val_accuracy: 0.8639\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.3281 - accuracy: 0.8839 - val_loss: 0.3763 - val_accuracy: 0.8667\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.3247 - accuracy: 0.8833 - val_loss: 0.3891 - val_accuracy: 0.8603\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.3235 - accuracy: 0.8841 - val_loss: 0.4096 - val_accuracy: 0.8584\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.3205 - accuracy: 0.8856 - val_loss: 0.3757 - val_accuracy: 0.8682\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.3183 - accuracy: 0.8874 - val_loss: 0.3884 - val_accuracy: 0.8646\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.3166 - accuracy: 0.8869 - val_loss: 0.3679 - val_accuracy: 0.8703\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.3136 - accuracy: 0.8890 - val_loss: 0.3743 - val_accuracy: 0.8694\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.3115 - accuracy: 0.8894 - val_loss: 0.3684 - val_accuracy: 0.8710\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.3106 - accuracy: 0.8891 - val_loss: 0.3835 - val_accuracy: 0.8648\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.3088 - accuracy: 0.8897 - val_loss: 0.3751 - val_accuracy: 0.8679\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.3056 - accuracy: 0.8909 - val_loss: 0.3696 - val_accuracy: 0.8719\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.3040 - accuracy: 0.8915 - val_loss: 0.3638 - val_accuracy: 0.8733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.3013 - accuracy: 0.8913 - val_loss: 0.3710 - val_accuracy: 0.8699\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.2991 - accuracy: 0.8946 - val_loss: 0.3611 - val_accuracy: 0.8722\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.2970 - accuracy: 0.8935 - val_loss: 0.3701 - val_accuracy: 0.8685\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 2s 25us/sample - loss: 0.2963 - accuracy: 0.8940 - val_loss: 0.3722 - val_accuracy: 0.8675\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.2938 - accuracy: 0.8949 - val_loss: 0.3592 - val_accuracy: 0.8747\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.2924 - accuracy: 0.8944 - val_loss: 0.3655 - val_accuracy: 0.8730\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.2906 - accuracy: 0.8952 - val_loss: 0.3652 - val_accuracy: 0.8706\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 2s 25us/sample - loss: 0.2893 - accuracy: 0.8964 - val_loss: 0.3633 - val_accuracy: 0.8700\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.2869 - accuracy: 0.8960 - val_loss: 0.3577 - val_accuracy: 0.8730\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 2s 25us/sample - loss: 0.2859 - accuracy: 0.8973 - val_loss: 0.3545 - val_accuracy: 0.8751\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.2844 - accuracy: 0.8984 - val_loss: 0.3538 - val_accuracy: 0.8767\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 0.2815 - accuracy: 0.8994 - val_loss: 0.3664 - val_accuracy: 0.8693\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.2805 - accuracy: 0.8987 - val_loss: 0.3593 - val_accuracy: 0.8736\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.2793 - accuracy: 0.8991 - val_loss: 0.3619 - val_accuracy: 0.8714\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.2776 - accuracy: 0.8995 - val_loss: 0.3547 - val_accuracy: 0.8764\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.2763 - accuracy: 0.9006 - val_loss: 0.3560 - val_accuracy: 0.8734\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 2s 25us/sample - loss: 0.2742 - accuracy: 0.9008 - val_loss: 0.3508 - val_accuracy: 0.8784\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 2s 25us/sample - loss: 0.2722 - accuracy: 0.9018 - val_loss: 0.3570 - val_accuracy: 0.8749\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.2709 - accuracy: 0.9022 - val_loss: 0.3651 - val_accuracy: 0.8747\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.2698 - accuracy: 0.9029 - val_loss: 0.3506 - val_accuracy: 0.8778\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.2681 - accuracy: 0.9029 - val_loss: 0.3504 - val_accuracy: 0.8778\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.2671 - accuracy: 0.9043 - val_loss: 0.3497 - val_accuracy: 0.8790\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.2662 - accuracy: 0.9046 - val_loss: 0.3478 - val_accuracy: 0.8782\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 2s 25us/sample - loss: 0.2643 - accuracy: 0.9051 - val_loss: 0.3573 - val_accuracy: 0.8729\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.2624 - accuracy: 0.9056 - val_loss: 0.3488 - val_accuracy: 0.8780\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 2s 25us/sample - loss: 0.2607 - accuracy: 0.9061 - val_loss: 0.3476 - val_accuracy: 0.8787\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.2590 - accuracy: 0.9073 - val_loss: 0.3456 - val_accuracy: 0.8793\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.2584 - accuracy: 0.9067 - val_loss: 0.3438 - val_accuracy: 0.8803\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.2565 - accuracy: 0.9075 - val_loss: 0.3433 - val_accuracy: 0.8813\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.2563 - accuracy: 0.9077 - val_loss: 0.3414 - val_accuracy: 0.8824\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.2544 - accuracy: 0.9086 - val_loss: 0.3555 - val_accuracy: 0.8739\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.2536 - accuracy: 0.9082 - val_loss: 0.3526 - val_accuracy: 0.8764\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.2526 - accuracy: 0.9087 - val_loss: 0.3557 - val_accuracy: 0.8762\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.2512 - accuracy: 0.9092 - val_loss: 0.3517 - val_accuracy: 0.8762\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 2s 25us/sample - loss: 0.2496 - accuracy: 0.9098 - val_loss: 0.3476 - val_accuracy: 0.8783\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.2475 - accuracy: 0.9107 - val_loss: 0.3695 - val_accuracy: 0.8689\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 2s 25us/sample - loss: 0.2466 - accuracy: 0.9108 - val_loss: 0.3518 - val_accuracy: 0.8775\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.2454 - accuracy: 0.9111 - val_loss: 0.3427 - val_accuracy: 0.8822\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 0.2442 - accuracy: 0.9125 - val_loss: 0.3550 - val_accuracy: 0.8753\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 0.2430 - accuracy: 0.9121 - val_loss: 0.3437 - val_accuracy: 0.8805\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 0.2430 - accuracy: 0.9123 - val_loss: 0.3544 - val_accuracy: 0.8774\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.2406 - accuracy: 0.9131 - val_loss: 0.3534 - val_accuracy: 0.8764\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.2410 - accuracy: 0.9134 - val_loss: 0.3624 - val_accuracy: 0.8738\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.2384 - accuracy: 0.9136 - val_loss: 0.3451 - val_accuracy: 0.8788\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.2380 - accuracy: 0.9138 - val_loss: 0.3449 - val_accuracy: 0.8809\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.2367 - accuracy: 0.9140 - val_loss: 0.3476 - val_accuracy: 0.8778\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 2s 32us/sample - loss: 0.2360 - accuracy: 0.9145 - val_loss: 0.3536 - val_accuracy: 0.8767\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 0.2340 - accuracy: 0.9157 - val_loss: 0.3426 - val_accuracy: 0.8820\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.2338 - accuracy: 0.9152 - val_loss: 0.3451 - val_accuracy: 0.8796\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.2306 - accuracy: 0.9165 - val_loss: 0.3472 - val_accuracy: 0.8787\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.2309 - accuracy: 0.9159 - val_loss: 0.3416 - val_accuracy: 0.8831\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x28323c1ddc8>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3.compile(loss = 'categorical_crossentropy', optimizer = 'sgd', metrics = ['accuracy'])\n",
    "\n",
    "model_3.fit(X_train, y_train_cat, validation_data = (X_test, y_test_cat), \n",
    "         epochs = 100, batch_size = 200, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Loss: 0.2309 <br>\n",
    "Train Accuracy: 0.9159 <br>\n",
    "Test Loss: 0.3416 <br>\n",
    "Test Accuracy: 0.8831 <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SGD had the smallest test loss and is the least overfit, so I will investigate the effect of deeper layers using this optimizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 4: 7 layers, SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4 = Sequential()\n",
    "model_4.add(Dense(128, input_dim = X_train.shape[1], activation = 'relu'))\n",
    "model_4.add(Dense(128, activation = 'relu'))\n",
    "model_4.add(Dense(64, activation = 'relu'))\n",
    "model_4.add(Dense(64, activation = 'relu'))\n",
    "model_4.add(Dense(32, activation = 'relu'))\n",
    "model_4.add(Dense(32, activation = 'relu'))\n",
    "model_4.add(Dense(10, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x00000283242D21F8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x00000283242D21F8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "60000/60000 [==============================] - 2s 38us/sample - loss: 1.7107 - accuracy: 0.4682 - val_loss: 1.0080 - val_accuracy: 0.6335\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 0.8575 - accuracy: 0.6840 - val_loss: 0.7847 - val_accuracy: 0.7212\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 2s 30us/sample - loss: 0.7124 - accuracy: 0.7387 - val_loss: 0.6729 - val_accuracy: 0.7558\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 2s 31us/sample - loss: 0.6285 - accuracy: 0.7670 - val_loss: 0.6553 - val_accuracy: 0.7576\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 2s 32us/sample - loss: 0.5840 - accuracy: 0.7829 - val_loss: 0.6135 - val_accuracy: 0.7713\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.5461 - accuracy: 0.7998 - val_loss: 0.5383 - val_accuracy: 0.8050\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 2s 30us/sample - loss: 0.5192 - accuracy: 0.8135 - val_loss: 0.5138 - val_accuracy: 0.8200\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 2s 30us/sample - loss: 0.4955 - accuracy: 0.8256 - val_loss: 0.5090 - val_accuracy: 0.8222\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 2s 31us/sample - loss: 0.4779 - accuracy: 0.8325 - val_loss: 0.4841 - val_accuracy: 0.8332\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 2s 30us/sample - loss: 0.4649 - accuracy: 0.8379 - val_loss: 0.4774 - val_accuracy: 0.8328\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.4504 - accuracy: 0.8424 - val_loss: 0.5227 - val_accuracy: 0.8192\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 2s 30us/sample - loss: 0.4380 - accuracy: 0.8453 - val_loss: 0.4677 - val_accuracy: 0.8328\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 0.4299 - accuracy: 0.8502 - val_loss: 0.4424 - val_accuracy: 0.8445\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 0.4172 - accuracy: 0.8541 - val_loss: 0.4673 - val_accuracy: 0.8329\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 0.4103 - accuracy: 0.8536 - val_loss: 0.4424 - val_accuracy: 0.8427\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 0.4040 - accuracy: 0.8580 - val_loss: 0.4294 - val_accuracy: 0.8494\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 0.3958 - accuracy: 0.8607 - val_loss: 0.4233 - val_accuracy: 0.8532\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 2s 30us/sample - loss: 0.3884 - accuracy: 0.8626 - val_loss: 0.4574 - val_accuracy: 0.8342\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 0.3816 - accuracy: 0.8653 - val_loss: 0.4136 - val_accuracy: 0.8576\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 0.3763 - accuracy: 0.8671 - val_loss: 0.4090 - val_accuracy: 0.8566\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 0.3716 - accuracy: 0.8687 - val_loss: 0.4121 - val_accuracy: 0.8564\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 0.3672 - accuracy: 0.8695 - val_loss: 0.4483 - val_accuracy: 0.8338\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 0.3619 - accuracy: 0.8716 - val_loss: 0.4021 - val_accuracy: 0.8564\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 0.3577 - accuracy: 0.8725 - val_loss: 0.4086 - val_accuracy: 0.8525\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 0.3526 - accuracy: 0.8752 - val_loss: 0.3928 - val_accuracy: 0.8601\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 0.3492 - accuracy: 0.8750 - val_loss: 0.3996 - val_accuracy: 0.8581\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 0.3442 - accuracy: 0.8773 - val_loss: 0.4149 - val_accuracy: 0.8534\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 0.3405 - accuracy: 0.8774 - val_loss: 0.4112 - val_accuracy: 0.8494\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 0.3355 - accuracy: 0.8785 - val_loss: 0.3984 - val_accuracy: 0.8582\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 0.3323 - accuracy: 0.8809 - val_loss: 0.3904 - val_accuracy: 0.8617\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 2s 30us/sample - loss: 0.3300 - accuracy: 0.8816 - val_loss: 0.3830 - val_accuracy: 0.8637\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.3259 - accuracy: 0.8824 - val_loss: 0.3897 - val_accuracy: 0.8613\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 2s 32us/sample - loss: 0.3223 - accuracy: 0.8827 - val_loss: 0.3889 - val_accuracy: 0.8604\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 2s 31us/sample - loss: 0.3178 - accuracy: 0.8858 - val_loss: 0.3693 - val_accuracy: 0.8663\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 2s 31us/sample - loss: 0.3138 - accuracy: 0.8863 - val_loss: 0.3863 - val_accuracy: 0.8622\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 2s 32us/sample - loss: 0.3123 - accuracy: 0.8866 - val_loss: 0.3786 - val_accuracy: 0.8624\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.3094 - accuracy: 0.8881 - val_loss: 0.3953 - val_accuracy: 0.8563\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.3081 - accuracy: 0.8879 - val_loss: 0.3696 - val_accuracy: 0.8650\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 2s 31us/sample - loss: 0.3032 - accuracy: 0.8896 - val_loss: 0.3773 - val_accuracy: 0.8640\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 2s 30us/sample - loss: 0.3011 - accuracy: 0.8914 - val_loss: 0.3754 - val_accuracy: 0.8639\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 2s 31us/sample - loss: 0.2999 - accuracy: 0.8903 - val_loss: 0.3706 - val_accuracy: 0.8687\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 2s 30us/sample - loss: 0.2966 - accuracy: 0.8921 - val_loss: 0.3670 - val_accuracy: 0.8695\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.2937 - accuracy: 0.8935 - val_loss: 0.3644 - val_accuracy: 0.8711\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.2913 - accuracy: 0.8941 - val_loss: 0.3655 - val_accuracy: 0.8710\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.2895 - accuracy: 0.8946 - val_loss: 0.3680 - val_accuracy: 0.8693\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.2859 - accuracy: 0.8963 - val_loss: 0.3649 - val_accuracy: 0.8679\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.2848 - accuracy: 0.8959 - val_loss: 0.3611 - val_accuracy: 0.8712\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 2s 31us/sample - loss: 0.2825 - accuracy: 0.8961 - val_loss: 0.3526 - val_accuracy: 0.8743\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 2s 31us/sample - loss: 0.2794 - accuracy: 0.8979 - val_loss: 0.3630 - val_accuracy: 0.8727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 0.2763 - accuracy: 0.8989 - val_loss: 0.3695 - val_accuracy: 0.8666\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 2s 30us/sample - loss: 0.2754 - accuracy: 0.8992 - val_loss: 0.3612 - val_accuracy: 0.8708\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 2s 30us/sample - loss: 0.2732 - accuracy: 0.9000 - val_loss: 0.3682 - val_accuracy: 0.8687\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 2s 31us/sample - loss: 0.2706 - accuracy: 0.9018 - val_loss: 0.3519 - val_accuracy: 0.8759\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 2s 31us/sample - loss: 0.2687 - accuracy: 0.9007 - val_loss: 0.3511 - val_accuracy: 0.8770\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 2s 30us/sample - loss: 0.2670 - accuracy: 0.9018 - val_loss: 0.3615 - val_accuracy: 0.8685\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 0.2645 - accuracy: 0.9029 - val_loss: 0.3542 - val_accuracy: 0.8769\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 0.2649 - accuracy: 0.9031 - val_loss: 0.3571 - val_accuracy: 0.8748\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 2s 31us/sample - loss: 0.2598 - accuracy: 0.9058 - val_loss: 0.3561 - val_accuracy: 0.8732\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 2s 30us/sample - loss: 0.2584 - accuracy: 0.9058 - val_loss: 0.3576 - val_accuracy: 0.8734\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 2s 30us/sample - loss: 0.2569 - accuracy: 0.9059 - val_loss: 0.3460 - val_accuracy: 0.8795\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 2s 30us/sample - loss: 0.2541 - accuracy: 0.9068 - val_loss: 0.3541 - val_accuracy: 0.8754\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 2s 30us/sample - loss: 0.2529 - accuracy: 0.9072 - val_loss: 0.3577 - val_accuracy: 0.8746\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 2s 30us/sample - loss: 0.2508 - accuracy: 0.9082 - val_loss: 0.3468 - val_accuracy: 0.8790\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 2s 30us/sample - loss: 0.2488 - accuracy: 0.9080 - val_loss: 0.3530 - val_accuracy: 0.8746\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 0.2487 - accuracy: 0.9092 - val_loss: 0.3759 - val_accuracy: 0.8695\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 2s 30us/sample - loss: 0.2480 - accuracy: 0.9087 - val_loss: 0.3585 - val_accuracy: 0.8756\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 0.2437 - accuracy: 0.9106 - val_loss: 0.3446 - val_accuracy: 0.8786\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 0.2434 - accuracy: 0.9111 - val_loss: 0.3430 - val_accuracy: 0.8782\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 0.2414 - accuracy: 0.9111 - val_loss: 0.3450 - val_accuracy: 0.8765\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 2s 30us/sample - loss: 0.2379 - accuracy: 0.9130 - val_loss: 0.3467 - val_accuracy: 0.8756\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 0.2378 - accuracy: 0.9123 - val_loss: 0.3598 - val_accuracy: 0.8767\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 2s 30us/sample - loss: 0.2377 - accuracy: 0.9118 - val_loss: 0.3866 - val_accuracy: 0.8633\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 2s 30us/sample - loss: 0.2343 - accuracy: 0.9151 - val_loss: 0.3477 - val_accuracy: 0.8784\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 2s 32us/sample - loss: 0.2331 - accuracy: 0.9153 - val_loss: 0.3891 - val_accuracy: 0.8621\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 0.2312 - accuracy: 0.9150 - val_loss: 0.3631 - val_accuracy: 0.8760\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 2s 30us/sample - loss: 0.2301 - accuracy: 0.9151 - val_loss: 0.3529 - val_accuracy: 0.8743\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 2s 30us/sample - loss: 0.2272 - accuracy: 0.9162 - val_loss: 0.4028 - val_accuracy: 0.8561\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 2s 30us/sample - loss: 0.2265 - accuracy: 0.9176 - val_loss: 0.3534 - val_accuracy: 0.8785\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 0.2246 - accuracy: 0.9178 - val_loss: 0.3562 - val_accuracy: 0.8746\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 2s 30us/sample - loss: 0.2243 - accuracy: 0.9179 - val_loss: 0.3458 - val_accuracy: 0.8804\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 3s 49us/sample - loss: 0.2213 - accuracy: 0.9184 - val_loss: 0.3543 - val_accuracy: 0.8776\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.2186 - accuracy: 0.9202 - val_loss: 0.3527 - val_accuracy: 0.8776\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.2175 - accuracy: 0.9207 - val_loss: 0.3628 - val_accuracy: 0.8748\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 2s 30us/sample - loss: 0.2179 - accuracy: 0.9195 - val_loss: 0.3443 - val_accuracy: 0.8828\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 2s 30us/sample - loss: 0.2148 - accuracy: 0.9209 - val_loss: 0.3443 - val_accuracy: 0.8810\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 2s 30us/sample - loss: 0.2151 - accuracy: 0.9209 - val_loss: 0.3744 - val_accuracy: 0.8670\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 2s 31us/sample - loss: 0.2111 - accuracy: 0.9233 - val_loss: 0.3483 - val_accuracy: 0.8807\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 2s 30us/sample - loss: 0.2116 - accuracy: 0.9229 - val_loss: 0.3488 - val_accuracy: 0.8820\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 2s 30us/sample - loss: 0.2086 - accuracy: 0.9234 - val_loss: 0.3468 - val_accuracy: 0.8800\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 2s 31us/sample - loss: 0.2110 - accuracy: 0.9223 - val_loss: 0.3511 - val_accuracy: 0.8802\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 2s 30us/sample - loss: 0.2067 - accuracy: 0.9247 - val_loss: 0.3449 - val_accuracy: 0.8816\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 2s 31us/sample - loss: 0.2054 - accuracy: 0.9253 - val_loss: 0.3489 - val_accuracy: 0.8811\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 2s 30us/sample - loss: 0.2039 - accuracy: 0.9252 - val_loss: 0.3477 - val_accuracy: 0.8791\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 2s 31us/sample - loss: 0.2050 - accuracy: 0.9241 - val_loss: 0.3568 - val_accuracy: 0.8784\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 2s 30us/sample - loss: 0.2014 - accuracy: 0.9263 - val_loss: 0.3570 - val_accuracy: 0.8782\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 2s 31us/sample - loss: 0.1984 - accuracy: 0.9273 - val_loss: 0.3461 - val_accuracy: 0.8829\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 2s 31us/sample - loss: 0.1988 - accuracy: 0.9269 - val_loss: 0.3489 - val_accuracy: 0.8808\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.1970 - accuracy: 0.9275 - val_loss: 0.3639 - val_accuracy: 0.8785\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 2s 31us/sample - loss: 0.1959 - accuracy: 0.9284 - val_loss: 0.3469 - val_accuracy: 0.8855\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 2s 31us/sample - loss: 0.1946 - accuracy: 0.9295 - val_loss: 0.3542 - val_accuracy: 0.8794\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x283242c4808>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_4.compile(loss = 'categorical_crossentropy', optimizer = 'sgd', metrics = ['accuracy'])\n",
    "\n",
    "model_4.fit(X_train, y_train_cat, validation_data = (X_test, y_test_cat), \n",
    "         epochs = 100, batch_size = 200, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Loss: 0.1946 <br>\n",
    "Train Accuracy: 0.9295 <br>\n",
    "Test Loss: 0.3542 <br>\n",
    "Test Accuracy: 0.8794 <br>\n",
    "\n",
    "Increasing the number of layers decreased loss very slightly and actually decreased accuracy. It may not be worth the extra computation for such little increase in performance. The models are slightly overfit, so adding dropout layers might be helpful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 5: 5 layers, SGD, with Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_5 = Sequential()\n",
    "model_5.add(Dropout(rate = 0.2, input_shape = (X_train.shape[1],)))\n",
    "model_5.add(Dense(128, activation = 'relu'))\n",
    "model_5.add(Dense(64, activation = 'relu'))\n",
    "model_5.add(Dense(64, activation = 'relu'))\n",
    "model_5.add(Dense(32, activation = 'relu'))\n",
    "model_5.add(Dense(10, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000028324CFC168> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000028324CFC168> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "60000/60000 [==============================] - 3s 53us/sample - loss: 0.6911 - accuracy: 0.7532 - val_loss: 0.5152 - val_accuracy: 0.8168\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 2s 38us/sample - loss: 0.4719 - accuracy: 0.8281 - val_loss: 0.4304 - val_accuracy: 0.8397\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.4220 - accuracy: 0.8445 - val_loss: 0.4340 - val_accuracy: 0.8424\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.3952 - accuracy: 0.8536 - val_loss: 0.3933 - val_accuracy: 0.8600\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 2s 38us/sample - loss: 0.3716 - accuracy: 0.8635 - val_loss: 0.3648 - val_accuracy: 0.8686\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.3555 - accuracy: 0.8677 - val_loss: 0.4111 - val_accuracy: 0.8476\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 2s 40us/sample - loss: 0.3451 - accuracy: 0.8717 - val_loss: 0.3604 - val_accuracy: 0.8730\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.3359 - accuracy: 0.8762 - val_loss: 0.3933 - val_accuracy: 0.8589\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 2s 41us/sample - loss: 0.3262 - accuracy: 0.8786 - val_loss: 0.3608 - val_accuracy: 0.8676\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 2s 40us/sample - loss: 0.3200 - accuracy: 0.8803 - val_loss: 0.3472 - val_accuracy: 0.8747\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 2s 38us/sample - loss: 0.3126 - accuracy: 0.8837 - val_loss: 0.3627 - val_accuracy: 0.8716\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 2s 38us/sample - loss: 0.3051 - accuracy: 0.8851 - val_loss: 0.3571 - val_accuracy: 0.8717\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.3010 - accuracy: 0.8873 - val_loss: 0.3629 - val_accuracy: 0.8691\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.2950 - accuracy: 0.8892 - val_loss: 0.3245 - val_accuracy: 0.8826\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.2911 - accuracy: 0.8903 - val_loss: 0.3260 - val_accuracy: 0.8824\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.2870 - accuracy: 0.8917 - val_loss: 0.3473 - val_accuracy: 0.8761\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 2s 40us/sample - loss: 0.2806 - accuracy: 0.8939 - val_loss: 0.3251 - val_accuracy: 0.8839\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.2788 - accuracy: 0.8945 - val_loss: 0.3346 - val_accuracy: 0.8775\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 2s 40us/sample - loss: 0.2747 - accuracy: 0.8970 - val_loss: 0.3312 - val_accuracy: 0.8853\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 2s 40us/sample - loss: 0.2730 - accuracy: 0.8976 - val_loss: 0.3170 - val_accuracy: 0.8863\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 2s 40us/sample - loss: 0.2698 - accuracy: 0.8973 - val_loss: 0.3228 - val_accuracy: 0.8872\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 3s 47us/sample - loss: 0.2653 - accuracy: 0.8995 - val_loss: 0.3235 - val_accuracy: 0.8869\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 3s 47us/sample - loss: 0.2649 - accuracy: 0.9009 - val_loss: 0.3399 - val_accuracy: 0.8844\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 3s 46us/sample - loss: 0.2627 - accuracy: 0.9007 - val_loss: 0.3381 - val_accuracy: 0.8819\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 0.2595 - accuracy: 0.9025 - val_loss: 0.3292 - val_accuracy: 0.8864\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 2s 40us/sample - loss: 0.2570 - accuracy: 0.9022 - val_loss: 0.3434 - val_accuracy: 0.8826\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 3s 46us/sample - loss: 0.2523 - accuracy: 0.9048 - val_loss: 0.3255 - val_accuracy: 0.8867\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 0.2526 - accuracy: 0.9039 - val_loss: 0.3313 - val_accuracy: 0.8881\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 2s 41us/sample - loss: 0.2514 - accuracy: 0.9057 - val_loss: 0.3255 - val_accuracy: 0.8863\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.2493 - accuracy: 0.9056 - val_loss: 0.3242 - val_accuracy: 0.8903\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.2475 - accuracy: 0.9060 - val_loss: 0.3126 - val_accuracy: 0.8918\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 0.2432 - accuracy: 0.9071 - val_loss: 0.3258 - val_accuracy: 0.8913\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 2s 42us/sample - loss: 0.2446 - accuracy: 0.9078 - val_loss: 0.3343 - val_accuracy: 0.8865\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 2s 42us/sample - loss: 0.2427 - accuracy: 0.9078 - val_loss: 0.3297 - val_accuracy: 0.8905\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 2s 41us/sample - loss: 0.2415 - accuracy: 0.9079 - val_loss: 0.3238 - val_accuracy: 0.8945\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 2s 41us/sample - loss: 0.2398 - accuracy: 0.9096 - val_loss: 0.3187 - val_accuracy: 0.8932\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 2s 41us/sample - loss: 0.2375 - accuracy: 0.9100 - val_loss: 0.3255 - val_accuracy: 0.8884\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 0.2362 - accuracy: 0.9103 - val_loss: 0.3460 - val_accuracy: 0.8847\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 2s 41us/sample - loss: 0.2379 - accuracy: 0.9110 - val_loss: 0.3241 - val_accuracy: 0.8891\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 2s 41us/sample - loss: 0.2349 - accuracy: 0.9116 - val_loss: 0.3321 - val_accuracy: 0.8889\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 2s 41us/sample - loss: 0.2334 - accuracy: 0.9117 - val_loss: 0.3611 - val_accuracy: 0.8893\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 2s 41us/sample - loss: 0.2318 - accuracy: 0.9121 - val_loss: 0.3262 - val_accuracy: 0.8923\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 2s 41us/sample - loss: 0.2316 - accuracy: 0.9125 - val_loss: 0.3292 - val_accuracy: 0.8906\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 2s 41us/sample - loss: 0.2327 - accuracy: 0.9118 - val_loss: 0.3230 - val_accuracy: 0.8940\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 2s 41us/sample - loss: 0.2286 - accuracy: 0.9142 - val_loss: 0.3292 - val_accuracy: 0.8936\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 0.2304 - accuracy: 0.9132 - val_loss: 0.3369 - val_accuracy: 0.8926\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 0.2302 - accuracy: 0.9120 - val_loss: 0.3354 - val_accuracy: 0.8895\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 0.2246 - accuracy: 0.9140 - val_loss: 0.3424 - val_accuracy: 0.8827\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 2s 42us/sample - loss: 0.2263 - accuracy: 0.9148 - val_loss: 0.3342 - val_accuracy: 0.8932\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 2s 38us/sample - loss: 0.2269 - accuracy: 0.9146 - val_loss: 0.3320 - val_accuracy: 0.8893\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 2s 38us/sample - loss: 0.2243 - accuracy: 0.9150 - val_loss: 0.3292 - val_accuracy: 0.8921\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 2s 38us/sample - loss: 0.2245 - accuracy: 0.9152 - val_loss: 0.3412 - val_accuracy: 0.8894\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.2239 - accuracy: 0.9151 - val_loss: 0.3389 - val_accuracy: 0.8901\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 2s 38us/sample - loss: 0.2237 - accuracy: 0.9154 - val_loss: 0.3401 - val_accuracy: 0.8891\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 2s 38us/sample - loss: 0.2210 - accuracy: 0.9170 - val_loss: 0.3486 - val_accuracy: 0.8932\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.2224 - accuracy: 0.9173 - val_loss: 0.3343 - val_accuracy: 0.8919\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 2s 38us/sample - loss: 0.2199 - accuracy: 0.9169 - val_loss: 0.3384 - val_accuracy: 0.8925\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.2232 - accuracy: 0.9159 - val_loss: 0.3603 - val_accuracy: 0.8911\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 2s 38us/sample - loss: 0.2185 - accuracy: 0.9176 - val_loss: 0.3647 - val_accuracy: 0.8890\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.2198 - accuracy: 0.9162 - val_loss: 0.3343 - val_accuracy: 0.8959\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.2190 - accuracy: 0.9170 - val_loss: 0.3404 - val_accuracy: 0.8968\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 2s 38us/sample - loss: 0.2153 - accuracy: 0.9189 - val_loss: 0.3488 - val_accuracy: 0.8879\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.2176 - accuracy: 0.9182 - val_loss: 0.3775 - val_accuracy: 0.8913\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.2154 - accuracy: 0.9190 - val_loss: 0.3400 - val_accuracy: 0.8928\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 2s 38us/sample - loss: 0.2180 - accuracy: 0.9169 - val_loss: 0.3535 - val_accuracy: 0.8936\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 2s 38us/sample - loss: 0.2185 - accuracy: 0.9171 - val_loss: 0.3473 - val_accuracy: 0.8915\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.2194 - accuracy: 0.9182 - val_loss: 0.3695 - val_accuracy: 0.8936\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.2156 - accuracy: 0.9195 - val_loss: 0.3609 - val_accuracy: 0.8876\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.2142 - accuracy: 0.9194 - val_loss: 0.3460 - val_accuracy: 0.8948\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 2s 38us/sample - loss: 0.2149 - accuracy: 0.9189 - val_loss: 0.3676 - val_accuracy: 0.8907\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.2150 - accuracy: 0.9176 - val_loss: 0.3550 - val_accuracy: 0.8929\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.2156 - accuracy: 0.9197 - val_loss: 0.3743 - val_accuracy: 0.8936\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.2129 - accuracy: 0.9192 - val_loss: 0.3622 - val_accuracy: 0.8926\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 0.2134 - accuracy: 0.9204 - val_loss: 0.3639 - val_accuracy: 0.8907\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 0.2135 - accuracy: 0.9195 - val_loss: 0.3644 - val_accuracy: 0.8966\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 2s 40us/sample - loss: 0.2124 - accuracy: 0.9208 - val_loss: 0.3664 - val_accuracy: 0.8938\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 0.2128 - accuracy: 0.9209 - val_loss: 0.3725 - val_accuracy: 0.8910\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 4s 60us/sample - loss: 0.2143 - accuracy: 0.9202 - val_loss: 0.3582 - val_accuracy: 0.8944\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 3s 46us/sample - loss: 0.2128 - accuracy: 0.9194 - val_loss: 0.3775 - val_accuracy: 0.8901\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 0.2115 - accuracy: 0.9202 - val_loss: 0.3879 - val_accuracy: 0.8898\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 0.2159 - accuracy: 0.9194 - val_loss: 0.3806 - val_accuracy: 0.8887\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 2s 41us/sample - loss: 0.2091 - accuracy: 0.9217 - val_loss: 0.3779 - val_accuracy: 0.8932\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 3s 45us/sample - loss: 0.2151 - accuracy: 0.9205 - val_loss: 0.3590 - val_accuracy: 0.8922\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 0.2111 - accuracy: 0.9211 - val_loss: 0.3460 - val_accuracy: 0.8967\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 2s 41us/sample - loss: 0.2123 - accuracy: 0.9213 - val_loss: 0.3941 - val_accuracy: 0.8880\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 2s 42us/sample - loss: 0.2103 - accuracy: 0.9217 - val_loss: 0.3711 - val_accuracy: 0.8930\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 2s 42us/sample - loss: 0.2101 - accuracy: 0.9222 - val_loss: 0.3736 - val_accuracy: 0.8918\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 0.2100 - accuracy: 0.9198 - val_loss: 0.3941 - val_accuracy: 0.8906\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 0.2136 - accuracy: 0.9208 - val_loss: 0.3722 - val_accuracy: 0.8918\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 0.2118 - accuracy: 0.9208 - val_loss: 0.3796 - val_accuracy: 0.8890\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 2s 41us/sample - loss: 0.2120 - accuracy: 0.9212 - val_loss: 0.3818 - val_accuracy: 0.8949\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 2s 41us/sample - loss: 0.2127 - accuracy: 0.9213 - val_loss: 0.3776 - val_accuracy: 0.8905\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 0.2104 - accuracy: 0.9212 - val_loss: 0.3681 - val_accuracy: 0.8917\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 2s 42us/sample - loss: 0.2098 - accuracy: 0.9235 - val_loss: 0.3959 - val_accuracy: 0.8914\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 2s 42us/sample - loss: 0.2107 - accuracy: 0.9212 - val_loss: 0.3811 - val_accuracy: 0.8915\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 2s 41us/sample - loss: 0.2104 - accuracy: 0.9220 - val_loss: 0.3733 - val_accuracy: 0.8945\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 2s 41us/sample - loss: 0.2086 - accuracy: 0.9222 - val_loss: 0.3898 - val_accuracy: 0.8915\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 0.2106 - accuracy: 0.9224 - val_loss: 0.3875 - val_accuracy: 0.8910\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 2s 41us/sample - loss: 0.2089 - accuracy: 0.9230 - val_loss: 0.3729 - val_accuracy: 0.8952\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 0.2076 - accuracy: 0.9219 - val_loss: 0.4050 - val_accuracy: 0.8921\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x28324ced948>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_5.compile(loss = 'categorical_crossentropy', optimizer = 'RMSprop', metrics = ['accuracy'])\n",
    "\n",
    "model_5.fit(X_train, y_train_cat, validation_data = (X_test, y_test_cat), \n",
    "        epochs = 100, batch_size = 200, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Loss: 0.2076 <br>\n",
    "Train Accuracy: 0.9219 <br>\n",
    "Test Loss: 0.4050<br>\n",
    "Test Accuracy: 0.8921 <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a dropout layer decreased overfitting, and increased accuracy. Depending on the use case for this model, this could be acceptable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.76      0.82      1000\n",
      "           1       0.99      0.98      0.98      1000\n",
      "           2       0.80      0.80      0.80      1000\n",
      "           3       0.86      0.94      0.90      1000\n",
      "           4       0.78      0.86      0.82      1000\n",
      "           5       0.99      0.97      0.98      1000\n",
      "           6       0.74      0.70      0.72      1000\n",
      "           7       0.95      0.97      0.96      1000\n",
      "           8       0.96      0.97      0.97      1000\n",
      "           9       0.96      0.97      0.96      1000\n",
      "\n",
      "    accuracy                           0.89     10000\n",
      "   macro avg       0.89      0.89      0.89     10000\n",
      "weighted avg       0.89      0.89      0.89     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model_5.predict_classes(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_df = pd.DataFrame(confusion_matrix(y_test, y_pred),\n",
    "                            index = ['T-shirt', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot'],\n",
    "                            columns = [' Pred T-shirt', 'Pred Trouser', 'Pred Pullover', 'Pred Dress', 'Pred Coat', 'Pred Sandal', 'Pred Shirt', 'Pred Sneaker', 'Pred Bag', 'Pred Ankle Boot'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pred T-shirt</th>\n",
       "      <th>Pred Trouser</th>\n",
       "      <th>Pred Pullover</th>\n",
       "      <th>Pred Dress</th>\n",
       "      <th>Pred Coat</th>\n",
       "      <th>Pred Sandal</th>\n",
       "      <th>Pred Shirt</th>\n",
       "      <th>Pred Sneaker</th>\n",
       "      <th>Pred Bag</th>\n",
       "      <th>Pred Ankle Boot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>T-shirt</th>\n",
       "      <td>761</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>44</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>151</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trouser</th>\n",
       "      <td>0</td>\n",
       "      <td>979</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pullover</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>802</td>\n",
       "      <td>14</td>\n",
       "      <td>129</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dress</th>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>939</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Coat</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>42</td>\n",
       "      <td>858</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sandal</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>967</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shirt</th>\n",
       "      <td>74</td>\n",
       "      <td>2</td>\n",
       "      <td>95</td>\n",
       "      <td>34</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>701</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sneaker</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>971</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bag</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>974</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ankle Boot</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>969</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Pred T-shirt  Pred Trouser  Pred Pullover  Pred Dress  Pred Coat  \\\n",
       "T-shirt               761             3             21          44          4   \n",
       "Trouser                 0           979              1          13          3   \n",
       "Pullover                9             1            802          14        129   \n",
       "Dress                   7             5             10         939         20   \n",
       "Coat                    0             0             66          42        858   \n",
       "Sandal                  0             0              0           1          0   \n",
       "Shirt                  74             2             95          34         83   \n",
       "Sneaker                 0             0              0           0          0   \n",
       "Bag                     0             0              2           5          7   \n",
       "Ankle Boot              0             0              0           0          0   \n",
       "\n",
       "            Pred Sandal  Pred Shirt  Pred Sneaker  Pred Bag  Pred Ankle Boot  \n",
       "T-shirt               0         151             0        16                0  \n",
       "Trouser               0           2             0         2                0  \n",
       "Pullover              0          43             0         2                0  \n",
       "Dress                 0          15             0         4                0  \n",
       "Coat                  0          33             0         1                0  \n",
       "Sandal              967           0            14         0               18  \n",
       "Shirt                 0         701             0        11                0  \n",
       "Sneaker               5           0           971         0               24  \n",
       "Bag                   3           5             4       974                0  \n",
       "Ankle Boot            1           1            29         0              969  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "The best model was 5 layers, used one dropout layer with a rate of 0.2, and a SGD optimizer. The model had the most difficulty classifiying class 4 and 6 (coats and shirts, respectively). Performance might be improved by adjusting the learning rate and momentum of the SGD optimizer."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
