{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install tensorflow==2.0.0-rc1 --quiet\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense, Conv2D, Dropout, Flatten\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.optimizers import Adam, SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_raw, y_train), (X_test_raw, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "# reshape to use in Dense layers\n",
    "X_train = X_train_raw.reshape(X_train_raw.shape[0], 28*28)\n",
    "X_test = X_test_raw.reshape(X_test_raw.shape[0], 28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert labels to numeric\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_conv = X_train_raw.reshape(X_train_raw.shape[0],X_train_raw.shape[1],X_train_raw.shape[1],1)\n",
    "X_test_conv = X_test_raw.reshape(X_test_raw.shape[0],X_test_raw.shape[1],X_test_raw.shape[1],1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28, 1)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_conv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 1.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1: 5 layers, Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = Sequential()\n",
    "model_1.add(Dense(128, input_dim = X_train.shape[1], activation = 'relu'))\n",
    "model_1.add(Dense(64, activation = 'relu'))\n",
    "model_1.add(Dense(64, activation = 'relu'))\n",
    "model_1.add(Dense(32, activation = 'relu'))\n",
    "model_1.add(Dense(10, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x000001903B7948B8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x000001903B7948B8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 1.2261 - accuracy: 0.5437 - val_loss: 0.8116 - val_accuracy: 0.6888\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.7468 - accuracy: 0.7224 - val_loss: 0.7460 - val_accuracy: 0.7290\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.6800 - accuracy: 0.7508 - val_loss: 0.6771 - val_accuracy: 0.7524\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.6353 - accuracy: 0.7678 - val_loss: 0.6366 - val_accuracy: 0.7709\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 2s 32us/sample - loss: 0.5953 - accuracy: 0.7835 - val_loss: 0.6017 - val_accuracy: 0.7837\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 0.5643 - accuracy: 0.7962 - val_loss: 0.5787 - val_accuracy: 0.7937\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 2s 30us/sample - loss: 0.5369 - accuracy: 0.8044 - val_loss: 0.5543 - val_accuracy: 0.8031\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.5134 - accuracy: 0.8146 - val_loss: 0.5278 - val_accuracy: 0.8128\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.4931 - accuracy: 0.8230 - val_loss: 0.5147 - val_accuracy: 0.8161\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 0.4746 - accuracy: 0.8298 - val_loss: 0.5056 - val_accuracy: 0.8164\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 0.4592 - accuracy: 0.8349 - val_loss: 0.4994 - val_accuracy: 0.8211\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 2s 31us/sample - loss: 0.4464 - accuracy: 0.8389 - val_loss: 0.4778 - val_accuracy: 0.8248\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.4317 - accuracy: 0.8439 - val_loss: 0.4716 - val_accuracy: 0.8323\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.4223 - accuracy: 0.8472 - val_loss: 0.4505 - val_accuracy: 0.8359\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 0.4089 - accuracy: 0.8515 - val_loss: 0.4378 - val_accuracy: 0.8430\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 2s 37us/sample - loss: 0.4018 - accuracy: 0.8554 - val_loss: 0.4340 - val_accuracy: 0.8405\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.3921 - accuracy: 0.8575 - val_loss: 0.4375 - val_accuracy: 0.8425\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 0.3835 - accuracy: 0.8599 - val_loss: 0.4390 - val_accuracy: 0.8380\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 2s 32us/sample - loss: 0.3798 - accuracy: 0.8625 - val_loss: 0.4329 - val_accuracy: 0.8430\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 2s 32us/sample - loss: 0.3732 - accuracy: 0.8643 - val_loss: 0.4107 - val_accuracy: 0.8540\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 0.3656 - accuracy: 0.8668 - val_loss: 0.4113 - val_accuracy: 0.8505\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.3593 - accuracy: 0.8699 - val_loss: 0.4178 - val_accuracy: 0.8463\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.3575 - accuracy: 0.8698 - val_loss: 0.4256 - val_accuracy: 0.8461\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 2s 31us/sample - loss: 0.3503 - accuracy: 0.8729 - val_loss: 0.3984 - val_accuracy: 0.8567\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 2s 32us/sample - loss: 0.3460 - accuracy: 0.8740 - val_loss: 0.3941 - val_accuracy: 0.8572\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 2s 32us/sample - loss: 0.3405 - accuracy: 0.8755 - val_loss: 0.3938 - val_accuracy: 0.8600\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.3360 - accuracy: 0.8777 - val_loss: 0.3952 - val_accuracy: 0.8565\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.3326 - accuracy: 0.8784 - val_loss: 0.3839 - val_accuracy: 0.8609\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 0.3292 - accuracy: 0.8804 - val_loss: 0.3840 - val_accuracy: 0.8613\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.3232 - accuracy: 0.8819 - val_loss: 0.3826 - val_accuracy: 0.8611\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 2s 38us/sample - loss: 0.3208 - accuracy: 0.8829 - val_loss: 0.3814 - val_accuracy: 0.8609\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.3185 - accuracy: 0.8844 - val_loss: 0.3761 - val_accuracy: 0.8651\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.3164 - accuracy: 0.8843 - val_loss: 0.3796 - val_accuracy: 0.8628\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 2s 38us/sample - loss: 0.3133 - accuracy: 0.8852 - val_loss: 0.3740 - val_accuracy: 0.8639\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.3087 - accuracy: 0.8875 - val_loss: 0.3740 - val_accuracy: 0.8649\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.3068 - accuracy: 0.8886 - val_loss: 0.3705 - val_accuracy: 0.8677\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.3006 - accuracy: 0.8906 - val_loss: 0.3704 - val_accuracy: 0.8673\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 2s 32us/sample - loss: 0.3005 - accuracy: 0.8890 - val_loss: 0.3657 - val_accuracy: 0.8689\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 2s 31us/sample - loss: 0.2966 - accuracy: 0.8910 - val_loss: 0.3632 - val_accuracy: 0.8695\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 2s 40us/sample - loss: 0.2936 - accuracy: 0.8917 - val_loss: 0.3619 - val_accuracy: 0.8692\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.2905 - accuracy: 0.8934 - val_loss: 0.3625 - val_accuracy: 0.8700\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 2s 37us/sample - loss: 0.2887 - accuracy: 0.8936 - val_loss: 0.3772 - val_accuracy: 0.8668\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 2s 38us/sample - loss: 0.2864 - accuracy: 0.8953 - val_loss: 0.4012 - val_accuracy: 0.8543\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.2838 - accuracy: 0.8960 - val_loss: 0.3563 - val_accuracy: 0.8748\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 2s 30us/sample - loss: 0.2799 - accuracy: 0.8972 - val_loss: 0.3901 - val_accuracy: 0.8641\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 2s 31us/sample - loss: 0.2790 - accuracy: 0.8978 - val_loss: 0.3644 - val_accuracy: 0.8678\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 2s 30us/sample - loss: 0.2776 - accuracy: 0.8980 - val_loss: 0.3625 - val_accuracy: 0.8729\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 2s 31us/sample - loss: 0.2732 - accuracy: 0.9008 - val_loss: 0.3687 - val_accuracy: 0.8696\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 2s 31us/sample - loss: 0.2700 - accuracy: 0.9014 - val_loss: 0.3711 - val_accuracy: 0.8687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 0.2698 - accuracy: 0.9008 - val_loss: 0.3645 - val_accuracy: 0.8707\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.2666 - accuracy: 0.9026 - val_loss: 0.3486 - val_accuracy: 0.8768\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 2s 30us/sample - loss: 0.2625 - accuracy: 0.9032 - val_loss: 0.3738 - val_accuracy: 0.8649\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 2s 30us/sample - loss: 0.2645 - accuracy: 0.9021 - val_loss: 0.3596 - val_accuracy: 0.8706\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 0.2590 - accuracy: 0.9036 - val_loss: 0.3561 - val_accuracy: 0.8719\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 0.2585 - accuracy: 0.9054 - val_loss: 0.3565 - val_accuracy: 0.8729\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 0.2568 - accuracy: 0.9053 - val_loss: 0.3495 - val_accuracy: 0.8757\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 0.2522 - accuracy: 0.9065 - val_loss: 0.3664 - val_accuracy: 0.8688\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 0.2495 - accuracy: 0.9084 - val_loss: 0.3503 - val_accuracy: 0.8772\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 0.2483 - accuracy: 0.9079 - val_loss: 0.3526 - val_accuracy: 0.8772\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 0.2479 - accuracy: 0.9082 - val_loss: 0.3545 - val_accuracy: 0.8759\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.2438 - accuracy: 0.9101 - val_loss: 0.3637 - val_accuracy: 0.8689\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.2450 - accuracy: 0.9097 - val_loss: 0.3586 - val_accuracy: 0.8740\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.2408 - accuracy: 0.9108 - val_loss: 0.3577 - val_accuracy: 0.8750\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.2396 - accuracy: 0.9113 - val_loss: 0.3586 - val_accuracy: 0.8760\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 2s 32us/sample - loss: 0.2356 - accuracy: 0.9132 - val_loss: 0.3528 - val_accuracy: 0.8774\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.2355 - accuracy: 0.9126 - val_loss: 0.3518 - val_accuracy: 0.8782\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 2s 40us/sample - loss: 0.2355 - accuracy: 0.9130 - val_loss: 0.3471 - val_accuracy: 0.8795\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 3s 46us/sample - loss: 0.2316 - accuracy: 0.9146 - val_loss: 0.3545 - val_accuracy: 0.8793\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.2312 - accuracy: 0.9157 - val_loss: 0.3591 - val_accuracy: 0.8782\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 2s 30us/sample - loss: 0.2264 - accuracy: 0.9172 - val_loss: 0.3491 - val_accuracy: 0.8801\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 2s 41us/sample - loss: 0.2262 - accuracy: 0.9163 - val_loss: 0.3499 - val_accuracy: 0.8779\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 2s 40us/sample - loss: 0.2216 - accuracy: 0.9178 - val_loss: 0.3506 - val_accuracy: 0.8799\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 2s 41us/sample - loss: 0.2225 - accuracy: 0.9165 - val_loss: 0.3580 - val_accuracy: 0.8775\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 0.2210 - accuracy: 0.9184 - val_loss: 0.3621 - val_accuracy: 0.8762\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 2s 37us/sample - loss: 0.2202 - accuracy: 0.9181 - val_loss: 0.3600 - val_accuracy: 0.8760\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.2173 - accuracy: 0.9199 - val_loss: 0.3594 - val_accuracy: 0.8772\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 2s 30us/sample - loss: 0.2204 - accuracy: 0.9191 - val_loss: 0.3714 - val_accuracy: 0.8763\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 2s 31us/sample - loss: 0.2141 - accuracy: 0.9206 - val_loss: 0.3545 - val_accuracy: 0.8812\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 2s 30us/sample - loss: 0.2130 - accuracy: 0.9212 - val_loss: 0.3564 - val_accuracy: 0.8796\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 3s 47us/sample - loss: 0.2091 - accuracy: 0.9229 - val_loss: 0.3534 - val_accuracy: 0.8818\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 2s 37us/sample - loss: 0.2109 - accuracy: 0.9227 - val_loss: 0.3586 - val_accuracy: 0.8803\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.2064 - accuracy: 0.9236 - val_loss: 0.3555 - val_accuracy: 0.8825\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 2s 31us/sample - loss: 0.2042 - accuracy: 0.9258 - val_loss: 0.3547 - val_accuracy: 0.8808\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 2s 30us/sample - loss: 0.2051 - accuracy: 0.9250 - val_loss: 0.3625 - val_accuracy: 0.8794\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 2s 30us/sample - loss: 0.2048 - accuracy: 0.9247 - val_loss: 0.3688 - val_accuracy: 0.8771\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 2s 30us/sample - loss: 0.2028 - accuracy: 0.9260 - val_loss: 0.3584 - val_accuracy: 0.8827\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 2s 31us/sample - loss: 0.1985 - accuracy: 0.9270 - val_loss: 0.3631 - val_accuracy: 0.8794\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 2s 32us/sample - loss: 0.1989 - accuracy: 0.9271 - val_loss: 0.3615 - val_accuracy: 0.8816\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 0.1939 - accuracy: 0.9295 - val_loss: 0.3851 - val_accuracy: 0.8753\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 0.1975 - accuracy: 0.9270 - val_loss: 0.3650 - val_accuracy: 0.8799\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 2s 30us/sample - loss: 0.1938 - accuracy: 0.9289 - val_loss: 0.3685 - val_accuracy: 0.8812\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 2s 30us/sample - loss: 0.1924 - accuracy: 0.9301 - val_loss: 0.3638 - val_accuracy: 0.8841\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 2s 30us/sample - loss: 0.1908 - accuracy: 0.9310 - val_loss: 0.3693 - val_accuracy: 0.8819\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 2s 31us/sample - loss: 0.1917 - accuracy: 0.9306 - val_loss: 0.3780 - val_accuracy: 0.8798\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 0.1889 - accuracy: 0.9314 - val_loss: 0.3681 - val_accuracy: 0.8815\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 2s 30us/sample - loss: 0.1844 - accuracy: 0.9327 - val_loss: 0.3646 - val_accuracy: 0.8819\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 2s 30us/sample - loss: 0.1839 - accuracy: 0.9329 - val_loss: 0.3739 - val_accuracy: 0.8792\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 0.1842 - accuracy: 0.9326 - val_loss: 0.3882 - val_accuracy: 0.8754\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 0.1823 - accuracy: 0.9334 - val_loss: 0.3838 - val_accuracy: 0.8778\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 0.1809 - accuracy: 0.9344 - val_loss: 0.3676 - val_accuracy: 0.8832\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1903b7a83c8>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "\n",
    "model_1.fit(X_train, y_train, validation_data = (X_test, y_test), \n",
    "         epochs = 100, batch_size = 200, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Loss: 0.1809 <br>\n",
    "Train Accuracy: 0.9344 <br>\n",
    "Test Loss: 0.3676 <br>\n",
    "Test Accuracy: 0.8832"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2: 5 layers, RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = Sequential()\n",
    "model_2.add(Dense(128, input_dim = X_train.shape[1], activation = 'relu'))\n",
    "model_2.add(Dense(64, activation = 'relu'))\n",
    "model_2.add(Dense(64, activation = 'relu'))\n",
    "model_2.add(Dense(32, activation = 'relu'))\n",
    "model_2.add(Dense(10, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x000001903BEE5558> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x000001903BEE5558> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "60000/60000 [==============================] - 3s 53us/sample - loss: 1.3961 - accuracy: 0.4527 - val_loss: 0.9602 - val_accuracy: 0.6322\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 2s 31us/sample - loss: 0.8819 - accuracy: 0.6607 - val_loss: 0.8296 - val_accuracy: 0.6840\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 2s 30us/sample - loss: 0.7516 - accuracy: 0.7202 - val_loss: 0.7160 - val_accuracy: 0.7395\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 2s 30us/sample - loss: 0.6692 - accuracy: 0.7543 - val_loss: 0.6320 - val_accuracy: 0.7703\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 2s 30us/sample - loss: 0.6093 - accuracy: 0.7741 - val_loss: 0.6075 - val_accuracy: 0.7885\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 0.5614 - accuracy: 0.7940 - val_loss: 0.5944 - val_accuracy: 0.7702\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 0.5308 - accuracy: 0.8074 - val_loss: 0.5301 - val_accuracy: 0.8067\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 2s 30us/sample - loss: 0.5043 - accuracy: 0.8180 - val_loss: 0.5591 - val_accuracy: 0.7999\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 0.4881 - accuracy: 0.8243 - val_loss: 0.4958 - val_accuracy: 0.8201\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 2s 30us/sample - loss: 0.4701 - accuracy: 0.8290 - val_loss: 0.4933 - val_accuracy: 0.8188\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 2s 30us/sample - loss: 0.4562 - accuracy: 0.8353 - val_loss: 0.5003 - val_accuracy: 0.8173\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 2s 31us/sample - loss: 0.4446 - accuracy: 0.8393 - val_loss: 0.4638 - val_accuracy: 0.8332\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 0.4314 - accuracy: 0.8425 - val_loss: 0.4451 - val_accuracy: 0.8374\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 0.4200 - accuracy: 0.8486 - val_loss: 0.5311 - val_accuracy: 0.8025\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 0.4095 - accuracy: 0.8503 - val_loss: 0.4448 - val_accuracy: 0.8369\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 2s 30us/sample - loss: 0.4002 - accuracy: 0.8546 - val_loss: 0.4380 - val_accuracy: 0.8386\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 2s 30us/sample - loss: 0.3918 - accuracy: 0.8565 - val_loss: 0.4558 - val_accuracy: 0.8345\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 2s 38us/sample - loss: 0.3820 - accuracy: 0.8602 - val_loss: 0.4222 - val_accuracy: 0.8460\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.3743 - accuracy: 0.8623 - val_loss: 0.4437 - val_accuracy: 0.8377\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 2s 38us/sample - loss: 0.3656 - accuracy: 0.8656 - val_loss: 0.4026 - val_accuracy: 0.8547\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 2s 41us/sample - loss: 0.3595 - accuracy: 0.8674 - val_loss: 0.3986 - val_accuracy: 0.8512\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 2s 37us/sample - loss: 0.3539 - accuracy: 0.8694 - val_loss: 0.4183 - val_accuracy: 0.8514\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.3474 - accuracy: 0.8728 - val_loss: 0.4015 - val_accuracy: 0.8511\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.3410 - accuracy: 0.8750 - val_loss: 0.3789 - val_accuracy: 0.8602\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.3359 - accuracy: 0.8764 - val_loss: 0.3830 - val_accuracy: 0.8617\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.3316 - accuracy: 0.8788 - val_loss: 0.3810 - val_accuracy: 0.8628\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.3274 - accuracy: 0.8801 - val_loss: 0.4113 - val_accuracy: 0.8477\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.3221 - accuracy: 0.8822 - val_loss: 0.3691 - val_accuracy: 0.8649\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 2s 30us/sample - loss: 0.3182 - accuracy: 0.8824 - val_loss: 0.3745 - val_accuracy: 0.8656\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 2s 38us/sample - loss: 0.3127 - accuracy: 0.8857 - val_loss: 0.3634 - val_accuracy: 0.8700\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.3097 - accuracy: 0.8870 - val_loss: 0.3564 - val_accuracy: 0.8680\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 2s 38us/sample - loss: 0.3045 - accuracy: 0.8888 - val_loss: 0.3889 - val_accuracy: 0.8625\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 2s 38us/sample - loss: 0.3031 - accuracy: 0.8885 - val_loss: 0.3620 - val_accuracy: 0.8702\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 0.2980 - accuracy: 0.8904 - val_loss: 0.3508 - val_accuracy: 0.8757\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.2940 - accuracy: 0.8913 - val_loss: 0.3772 - val_accuracy: 0.8673\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.2908 - accuracy: 0.8941 - val_loss: 0.3790 - val_accuracy: 0.8632\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.2885 - accuracy: 0.8942 - val_loss: 0.3473 - val_accuracy: 0.8767\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.2855 - accuracy: 0.8948 - val_loss: 0.3467 - val_accuracy: 0.8759\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.2823 - accuracy: 0.8963 - val_loss: 0.3536 - val_accuracy: 0.8762\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.2797 - accuracy: 0.8968 - val_loss: 0.3440 - val_accuracy: 0.8792\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.2760 - accuracy: 0.8978 - val_loss: 0.3421 - val_accuracy: 0.8791\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.2730 - accuracy: 0.8989 - val_loss: 0.3404 - val_accuracy: 0.8772\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.2704 - accuracy: 0.9005 - val_loss: 0.3414 - val_accuracy: 0.8803\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.2671 - accuracy: 0.9010 - val_loss: 0.3401 - val_accuracy: 0.8802\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.2665 - accuracy: 0.9013 - val_loss: 0.3742 - val_accuracy: 0.8634\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.2623 - accuracy: 0.9029 - val_loss: 0.3539 - val_accuracy: 0.8733\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 2s 37us/sample - loss: 0.2602 - accuracy: 0.9038 - val_loss: 0.3360 - val_accuracy: 0.8858\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.2556 - accuracy: 0.9052 - val_loss: 0.3590 - val_accuracy: 0.8718\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 0.2552 - accuracy: 0.9046 - val_loss: 0.3409 - val_accuracy: 0.8805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 0.2520 - accuracy: 0.9072 - val_loss: 0.3278 - val_accuracy: 0.8848\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.2503 - accuracy: 0.9078 - val_loss: 0.3479 - val_accuracy: 0.8785\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 2s 32us/sample - loss: 0.2468 - accuracy: 0.9085 - val_loss: 0.3352 - val_accuracy: 0.8823\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 2s 40us/sample - loss: 0.2451 - accuracy: 0.9090 - val_loss: 0.3534 - val_accuracy: 0.8765\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 2s 38us/sample - loss: 0.2421 - accuracy: 0.9104 - val_loss: 0.3703 - val_accuracy: 0.8731\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 2s 41us/sample - loss: 0.2406 - accuracy: 0.9114 - val_loss: 0.3549 - val_accuracy: 0.8780\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.2392 - accuracy: 0.9114 - val_loss: 0.3664 - val_accuracy: 0.8755\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 2s 30us/sample - loss: 0.2363 - accuracy: 0.9116 - val_loss: 0.3402 - val_accuracy: 0.8853\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.2348 - accuracy: 0.9135 - val_loss: 0.3415 - val_accuracy: 0.8840\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.2323 - accuracy: 0.9139 - val_loss: 0.3448 - val_accuracy: 0.8803\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.2297 - accuracy: 0.9154 - val_loss: 0.3396 - val_accuracy: 0.8839\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.2285 - accuracy: 0.9148 - val_loss: 0.3481 - val_accuracy: 0.8819\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.2275 - accuracy: 0.9154 - val_loss: 0.3370 - val_accuracy: 0.8813\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.2255 - accuracy: 0.9156 - val_loss: 0.3434 - val_accuracy: 0.8810\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 2s 31us/sample - loss: 0.2223 - accuracy: 0.9171 - val_loss: 0.3346 - val_accuracy: 0.8860\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.2202 - accuracy: 0.9177 - val_loss: 0.3350 - val_accuracy: 0.8876\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.2194 - accuracy: 0.9182 - val_loss: 0.3344 - val_accuracy: 0.8855\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.2164 - accuracy: 0.9195 - val_loss: 0.3594 - val_accuracy: 0.8746\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.2149 - accuracy: 0.9206 - val_loss: 0.3385 - val_accuracy: 0.8865\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.2131 - accuracy: 0.9211 - val_loss: 0.3994 - val_accuracy: 0.8626\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 3s 48us/sample - loss: 0.2116 - accuracy: 0.9219 - val_loss: 0.3530 - val_accuracy: 0.8811\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 2s 30us/sample - loss: 0.2097 - accuracy: 0.9218 - val_loss: 0.3407 - val_accuracy: 0.8878\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.2066 - accuracy: 0.9231 - val_loss: 0.3383 - val_accuracy: 0.8871\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.2067 - accuracy: 0.9223 - val_loss: 0.3458 - val_accuracy: 0.8831\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.2031 - accuracy: 0.9238 - val_loss: 0.3460 - val_accuracy: 0.8883\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.2038 - accuracy: 0.9244 - val_loss: 0.3681 - val_accuracy: 0.8790\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.2004 - accuracy: 0.9256 - val_loss: 0.3474 - val_accuracy: 0.8861\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.1995 - accuracy: 0.9268 - val_loss: 0.3422 - val_accuracy: 0.8865\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.1978 - accuracy: 0.9265 - val_loss: 0.3462 - val_accuracy: 0.8844\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.1961 - accuracy: 0.9271 - val_loss: 0.3656 - val_accuracy: 0.8836\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.1938 - accuracy: 0.9272 - val_loss: 0.3462 - val_accuracy: 0.8894\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.1924 - accuracy: 0.9286 - val_loss: 0.3758 - val_accuracy: 0.8779\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.1920 - accuracy: 0.9292 - val_loss: 0.3498 - val_accuracy: 0.8875\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.1896 - accuracy: 0.9297 - val_loss: 0.3999 - val_accuracy: 0.8755\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 2s 32us/sample - loss: 0.1883 - accuracy: 0.9302 - val_loss: 0.3598 - val_accuracy: 0.8862\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 2s 30us/sample - loss: 0.1867 - accuracy: 0.9308 - val_loss: 0.3618 - val_accuracy: 0.8830\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 0.1856 - accuracy: 0.9308 - val_loss: 0.3558 - val_accuracy: 0.8884\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 0.1841 - accuracy: 0.9307 - val_loss: 0.3707 - val_accuracy: 0.8818\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.1828 - accuracy: 0.9318 - val_loss: 0.3537 - val_accuracy: 0.8869\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.1798 - accuracy: 0.9329 - val_loss: 0.3516 - val_accuracy: 0.8889\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.1785 - accuracy: 0.9330 - val_loss: 0.3525 - val_accuracy: 0.8877\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.1789 - accuracy: 0.9330 - val_loss: 0.3567 - val_accuracy: 0.8875\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.1776 - accuracy: 0.9337 - val_loss: 0.3642 - val_accuracy: 0.8876\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.1757 - accuracy: 0.9340 - val_loss: 0.3756 - val_accuracy: 0.8790\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.1743 - accuracy: 0.9353 - val_loss: 0.3816 - val_accuracy: 0.8790\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.1737 - accuracy: 0.9362 - val_loss: 0.3513 - val_accuracy: 0.8887\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.1710 - accuracy: 0.9363 - val_loss: 0.3645 - val_accuracy: 0.8879\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.1712 - accuracy: 0.9363 - val_loss: 0.3739 - val_accuracy: 0.8849\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.1711 - accuracy: 0.9360 - val_loss: 0.3533 - val_accuracy: 0.8934\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.1681 - accuracy: 0.9367 - val_loss: 0.3727 - val_accuracy: 0.8879\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.1684 - accuracy: 0.9373 - val_loss: 0.3622 - val_accuracy: 0.8868\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1903bedcb88>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.compile(loss = 'categorical_crossentropy', optimizer = 'RMSprop', metrics = ['accuracy'])\n",
    "\n",
    "model_2.fit(X_train, y_train, validation_data = (X_test, y_test), \n",
    "         epochs = 100, batch_size = 200, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Loss: 0.1684<br>\n",
    "Train Accuracy: 0.9373 <br>\n",
    "Test Loss: 0.3622 <br>\n",
    "Test Accuracy: 0.8868 <br>\n",
    "\n",
    "Using RMSprop as the optimizer very slightly improves accuracy and loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3: 7 layers, RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3 = Sequential()\n",
    "model_3.add(Dense(128, input_dim = X_train.shape[1], activation = 'relu'))\n",
    "model_3.add(Dense(128, activation = 'relu'))\n",
    "model_3.add(Dense(64, activation = 'relu'))\n",
    "model_3.add(Dense(64, activation = 'relu'))\n",
    "model_3.add(Dense(32, activation = 'relu'))\n",
    "model_3.add(Dense(32, activation = 'relu'))\n",
    "model_3.add(Dense(10, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x000001903FB7ACA8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x000001903FB7ACA8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "60000/60000 [==============================] - 3s 52us/sample - loss: 1.4538 - accuracy: 0.3935 - val_loss: 1.0591 - val_accuracy: 0.5205\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 1.0422 - accuracy: 0.5487 - val_loss: 0.9517 - val_accuracy: 0.5836\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.9252 - accuracy: 0.6129 - val_loss: 0.8279 - val_accuracy: 0.6731\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.7910 - accuracy: 0.6864 - val_loss: 0.6894 - val_accuracy: 0.7466\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.6922 - accuracy: 0.7322 - val_loss: 0.6591 - val_accuracy: 0.7479\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.6333 - accuracy: 0.7577 - val_loss: 0.6459 - val_accuracy: 0.7449\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 2s 32us/sample - loss: 0.5852 - accuracy: 0.7775 - val_loss: 0.6386 - val_accuracy: 0.7535\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.5552 - accuracy: 0.7892 - val_loss: 0.5359 - val_accuracy: 0.7982\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 2s 32us/sample - loss: 0.5237 - accuracy: 0.8031 - val_loss: 0.5151 - val_accuracy: 0.8088\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 2s 32us/sample - loss: 0.4999 - accuracy: 0.8123 - val_loss: 0.5004 - val_accuracy: 0.8184\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 2s 32us/sample - loss: 0.4752 - accuracy: 0.8227 - val_loss: 0.5511 - val_accuracy: 0.7901\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.4511 - accuracy: 0.8338 - val_loss: 0.4500 - val_accuracy: 0.8367\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 2s 32us/sample - loss: 0.4256 - accuracy: 0.8453 - val_loss: 0.4300 - val_accuracy: 0.8455\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 2s 31us/sample - loss: 0.4023 - accuracy: 0.8526 - val_loss: 0.4528 - val_accuracy: 0.8363\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 2s 31us/sample - loss: 0.3880 - accuracy: 0.8575 - val_loss: 0.4152 - val_accuracy: 0.8483\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 2s 31us/sample - loss: 0.3737 - accuracy: 0.8616 - val_loss: 0.4202 - val_accuracy: 0.8426\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 2s 31us/sample - loss: 0.3643 - accuracy: 0.8660 - val_loss: 0.4084 - val_accuracy: 0.8539\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 2s 31us/sample - loss: 0.3566 - accuracy: 0.8690 - val_loss: 0.3803 - val_accuracy: 0.8620\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.3475 - accuracy: 0.8728 - val_loss: 0.3788 - val_accuracy: 0.8640\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.3387 - accuracy: 0.8752 - val_loss: 0.4130 - val_accuracy: 0.8497\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.3339 - accuracy: 0.8770 - val_loss: 0.4187 - val_accuracy: 0.8473\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.3298 - accuracy: 0.8792 - val_loss: 0.4109 - val_accuracy: 0.8528\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.3209 - accuracy: 0.8825 - val_loss: 0.4128 - val_accuracy: 0.8548\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.3171 - accuracy: 0.8831 - val_loss: 0.3810 - val_accuracy: 0.8663\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 2s 37us/sample - loss: 0.3120 - accuracy: 0.8858 - val_loss: 0.3675 - val_accuracy: 0.8690\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.3082 - accuracy: 0.8873 - val_loss: 0.3704 - val_accuracy: 0.8653\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.3045 - accuracy: 0.8876 - val_loss: 0.3559 - val_accuracy: 0.8744\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.2989 - accuracy: 0.8893 - val_loss: 0.3732 - val_accuracy: 0.8683\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.2963 - accuracy: 0.8911 - val_loss: 0.3543 - val_accuracy: 0.8687\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.2919 - accuracy: 0.8940 - val_loss: 0.3449 - val_accuracy: 0.8807\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.2878 - accuracy: 0.8935 - val_loss: 0.3484 - val_accuracy: 0.8763\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.2852 - accuracy: 0.8960 - val_loss: 0.3568 - val_accuracy: 0.8705\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 0.2807 - accuracy: 0.8977 - val_loss: 0.3520 - val_accuracy: 0.8748\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.2778 - accuracy: 0.8977 - val_loss: 0.3437 - val_accuracy: 0.8804\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.2759 - accuracy: 0.8991 - val_loss: 0.3461 - val_accuracy: 0.8788\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 2s 37us/sample - loss: 0.2721 - accuracy: 0.9002 - val_loss: 0.3447 - val_accuracy: 0.8780\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.2682 - accuracy: 0.9004 - val_loss: 0.3661 - val_accuracy: 0.8720\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.2668 - accuracy: 0.9009 - val_loss: 0.3355 - val_accuracy: 0.8818\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.2625 - accuracy: 0.9036 - val_loss: 0.3578 - val_accuracy: 0.8770\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.2595 - accuracy: 0.9039 - val_loss: 0.3537 - val_accuracy: 0.8765\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.2571 - accuracy: 0.9051 - val_loss: 0.3449 - val_accuracy: 0.8802\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.2553 - accuracy: 0.9050 - val_loss: 0.3439 - val_accuracy: 0.8808\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.2516 - accuracy: 0.9068 - val_loss: 0.3503 - val_accuracy: 0.8783\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.2490 - accuracy: 0.9074 - val_loss: 0.3532 - val_accuracy: 0.8787\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 0.2469 - accuracy: 0.9085 - val_loss: 0.3414 - val_accuracy: 0.8844\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.2453 - accuracy: 0.9089 - val_loss: 0.3533 - val_accuracy: 0.8783\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.2441 - accuracy: 0.9083 - val_loss: 0.3494 - val_accuracy: 0.8811\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.2401 - accuracy: 0.9108 - val_loss: 0.3780 - val_accuracy: 0.8768\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.2375 - accuracy: 0.9114 - val_loss: 0.3464 - val_accuracy: 0.8854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.2344 - accuracy: 0.9123 - val_loss: 0.3370 - val_accuracy: 0.8840\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 3s 55us/sample - loss: 0.2335 - accuracy: 0.9132 - val_loss: 0.3452 - val_accuracy: 0.8785\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 3s 45us/sample - loss: 0.2309 - accuracy: 0.9142 - val_loss: 0.3514 - val_accuracy: 0.8823\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 2s 38us/sample - loss: 0.2291 - accuracy: 0.9145 - val_loss: 0.3462 - val_accuracy: 0.8852\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.2263 - accuracy: 0.9156 - val_loss: 0.3531 - val_accuracy: 0.8784\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 2s 37us/sample - loss: 0.2247 - accuracy: 0.9162 - val_loss: 0.3638 - val_accuracy: 0.8779\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.2215 - accuracy: 0.9167 - val_loss: 0.3462 - val_accuracy: 0.8833\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 2s 32us/sample - loss: 0.2190 - accuracy: 0.9191 - val_loss: 0.3682 - val_accuracy: 0.8779\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.2181 - accuracy: 0.9182 - val_loss: 0.3514 - val_accuracy: 0.8837\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.2155 - accuracy: 0.9201 - val_loss: 0.3606 - val_accuracy: 0.8856\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.2157 - accuracy: 0.9182 - val_loss: 0.3607 - val_accuracy: 0.8801\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.2117 - accuracy: 0.9206 - val_loss: 0.4143 - val_accuracy: 0.8703\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.2107 - accuracy: 0.9214 - val_loss: 0.3262 - val_accuracy: 0.8900\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.2080 - accuracy: 0.9222 - val_loss: 0.3461 - val_accuracy: 0.8870\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.2076 - accuracy: 0.9230 - val_loss: 0.3685 - val_accuracy: 0.8824\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.2052 - accuracy: 0.9228 - val_loss: 0.3540 - val_accuracy: 0.8850\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 2s 37us/sample - loss: 0.2039 - accuracy: 0.9232 - val_loss: 0.3353 - val_accuracy: 0.8871\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.2024 - accuracy: 0.9234 - val_loss: 0.3759 - val_accuracy: 0.8821\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 0.2022 - accuracy: 0.9253 - val_loss: 0.3806 - val_accuracy: 0.8802\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 3s 45us/sample - loss: 0.1988 - accuracy: 0.9265 - val_loss: 0.3826 - val_accuracy: 0.8781\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 2s 32us/sample - loss: 0.1983 - accuracy: 0.9251 - val_loss: 0.3466 - val_accuracy: 0.8888\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.1968 - accuracy: 0.9265 - val_loss: 0.3421 - val_accuracy: 0.8907\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.1946 - accuracy: 0.9267 - val_loss: 0.3682 - val_accuracy: 0.8847\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.1936 - accuracy: 0.9276 - val_loss: 0.3779 - val_accuracy: 0.8859\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.1910 - accuracy: 0.9289 - val_loss: 0.3650 - val_accuracy: 0.8863\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.1904 - accuracy: 0.9288 - val_loss: 0.3875 - val_accuracy: 0.8815\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 2s 32us/sample - loss: 0.1879 - accuracy: 0.9297 - val_loss: 0.4187 - val_accuracy: 0.8820\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.1862 - accuracy: 0.9296 - val_loss: 0.3664 - val_accuracy: 0.8825\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.1851 - accuracy: 0.9301 - val_loss: 0.3758 - val_accuracy: 0.8874\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 2s 38us/sample - loss: 0.1841 - accuracy: 0.9312 - val_loss: 0.4149 - val_accuracy: 0.8836\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 0.1808 - accuracy: 0.9331 - val_loss: 0.4106 - val_accuracy: 0.8760\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 3s 52us/sample - loss: 0.1809 - accuracy: 0.9312 - val_loss: 0.3795 - val_accuracy: 0.8871\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 2s 37us/sample - loss: 0.1807 - accuracy: 0.9328 - val_loss: 0.4051 - val_accuracy: 0.8843\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 2s 38us/sample - loss: 0.1768 - accuracy: 0.9338 - val_loss: 0.3817 - val_accuracy: 0.8853\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 2s 38us/sample - loss: 0.1777 - accuracy: 0.9344 - val_loss: 0.4049 - val_accuracy: 0.8827\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.1764 - accuracy: 0.9339 - val_loss: 0.4048 - val_accuracy: 0.8837\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 2s 37us/sample - loss: 0.1750 - accuracy: 0.9346 - val_loss: 0.4126 - val_accuracy: 0.8836\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.1718 - accuracy: 0.9352 - val_loss: 0.3951 - val_accuracy: 0.8851\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 3s 51us/sample - loss: 0.1711 - accuracy: 0.9368 - val_loss: 0.4157 - val_accuracy: 0.8827\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.1695 - accuracy: 0.9355 - val_loss: 0.3986 - val_accuracy: 0.8906\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.1692 - accuracy: 0.9363 - val_loss: 0.3726 - val_accuracy: 0.8888\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.1675 - accuracy: 0.9380 - val_loss: 0.3774 - val_accuracy: 0.8879\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.1676 - accuracy: 0.9367 - val_loss: 0.3902 - val_accuracy: 0.8868\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.1650 - accuracy: 0.9379 - val_loss: 0.4232 - val_accuracy: 0.8828\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.1638 - accuracy: 0.9380 - val_loss: 0.3874 - val_accuracy: 0.8885\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.1621 - accuracy: 0.9390 - val_loss: 0.4642 - val_accuracy: 0.8801\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.1623 - accuracy: 0.9390 - val_loss: 0.4039 - val_accuracy: 0.8867\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.1611 - accuracy: 0.9396 - val_loss: 0.4019 - val_accuracy: 0.8888\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.1593 - accuracy: 0.9391 - val_loss: 0.4559 - val_accuracy: 0.8792\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.1586 - accuracy: 0.9403 - val_loss: 0.4540 - val_accuracy: 0.8800\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.1571 - accuracy: 0.9407 - val_loss: 0.4407 - val_accuracy: 0.8878\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1903fb8de08>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3.compile(loss = 'categorical_crossentropy', optimizer = 'RMSprop', metrics = ['accuracy'])\n",
    "\n",
    "model_3.fit(X_train, y_train, validation_data = (X_test, y_test), \n",
    "         epochs = 100, batch_size = 200, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Loss: 0.1571 <br>\n",
    "Train Accuracy: 0.9407 <br>\n",
    "Test Loss: 0.4407 <br>\n",
    "Test Accuracy: 0.8878 <br>\n",
    "\n",
    "Increasing the number of layers increased accuracy and decreased loss very slightly. It may not be worth the extra computation for such little increase in performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv = Sequential()\n",
    "model_conv.add(Conv2D(128, input_shape = (28, 28,1), kernel_size = (3,3), activation = 'relu'))\n",
    "model_conv.add(Conv2D(128, kernel_size = (3,3), activation = 'relu'))\n",
    "model_conv.add(Flatten())\n",
    "model_conv.add(Dense(64, activation = 'relu'))\n",
    "model_conv.add(Dense(32, activation = 'relu'))\n",
    "model_conv.add(Dense(10, activation ='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000019041F56168> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000019041F56168> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "60000/60000 [==============================] - 527s 9ms/sample - loss: nan - accuracy: 0.0999 - val_loss: nan - val_accuracy: 0.1000\n",
      "Epoch 2/20\n",
      " 6800/60000 [==>...........................] - ETA: 7:03 - loss: nan - accuracy: 0.0996"
     ]
    }
   ],
   "source": [
    "model_conv.compile(loss = 'categorical_crossentropy', optimizer = 'sgd', metrics = ['accuracy'])\n",
    "\n",
    "model_conv.fit(X_train_conv, y_train, validation_data = (X_test_conv, y_test), \n",
    "         epochs = 20, batch_size = 100, verbose = 1)\n",
    "\n",
    "# I only use 20 epochs to cut down on computing time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
